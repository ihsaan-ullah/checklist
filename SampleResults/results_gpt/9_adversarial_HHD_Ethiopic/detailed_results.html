<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        box-sizing: border-box;
    }
    .container {
        margin: 20px auto;
        padding: 0 20px;
        position: relative;
    }
    .button {
        padding: 10px;
        font-size: 16px;
        text-align: center;
        background-color: #f93361;
        color: #fff;
        border: none;
        border-radius: 5px;
        cursor: pointer;
        text-decoration: none;
    }
    .button:hover {
        background-color: #bc0530;
    }
    .content {
        padding-top: 60px;
        padding-bottom: 40px;
        margin-bottom: 20px;
    }
    h1 {
        margin-top: 0;
        margin-bottom: 30px;
    }
    hr {
        margin-top: 50px;
        margin-bottom: 50px;
    }
    .review {
        margin-bottom: 30px;
        border: 1px solid #ccc;
        padding: 20px;
        border-radius: 5px;
        background-color: #f9f9f9;
    }
    .review h2 {
        margin-top: 0;
    }
    .review p {
        margin: 10px 0;
    }
    .question {
        /* color: #0033ff; */
        color: #000;
    }
    .answer {
        /* color: #28a745; */
        color: #000;
    }
    .justification {
        /* color: #de750b; */
        color: #000;
    }
    .user_input {
        padding: 20px;
        border-radius: 5px;
        background-color: #fff;
        border: 1px solid #3a3a3a;
    }
    .llm_review {
        color: #000;
        padding: 20px;
        border-radius: 5px;
        margin-top: 10px;
        margin-bottom: 10px;
    }
    .llm_review-red {
        background-color: #eacfcf;
        border: 1px solid #FF0000;
    }
    .llm_review-green {
        background-color: #c6e9c6;
        border: 1px solid #008000;

    }
    .llm_review-orange {
        background-color: #ebdecf;
        border: 1px solid #FF8C00;
    }
    table {
        border-collapse: collapse;
    }
    th, td {
        padding: 8px;
        text-align: left;
        border-bottom: 1px solid #ddd;
    }
    th {
        background-color: #f2f2f2;
    }
    .score-label {
        display: inline-block;
        padding: 5px 15px;
        border-radius: 5px;
        text-decoration: none;
    }
    .score-green {
        background-color: #c6e9c6;
        color: #000;
        border: 1px solid #008000;
    }
    .score-red {
        background-color: #eacfcf;
        color: #000;
        border: 1px solid #FF0000;
    }
    .score-orange {
        background-color: #ebdecf;
        color: #000;
        border: 1px solid #FF8C00;
    }
    .score-blue {
        background-color: #c8d8e6;
        color: #1b455e;
        border: 1px solid #1b455e;
    }
    .score-purple {
        background-color: #cac4e7;
        color: #271b5e;
        border: 1px solid #271b5e;
    }
    .scroll-button {
        padding: 5px 15px;
        font-size: 14px;
        cursor: pointer;
        text-decoration: none;
        border-radius: 3px;
        margin-top: 10px;
        margin-bottom: 10px;
    }
    .button-green{
        background-color: #c6e9c6;
        color: #000;
        border: 1px solid #008000;
    }
    .button-orange{
        background-color: #ebdecf;
        color: #000;
        border: 1px solid #FF8C00;
    }
    .button-orange:hover {
        background-color: #623600;
        color: #fff;
        border: none;
    }
    .button-green:hover {
        background-color: #015f01;
        color: #fff;
        border: none;
    }
    .move-to-top {
        padding: 5px 10px;
        font-size: 12px;
        color: #212121;
        border: 1px solid #212121;
        border-radius: 3px;
        cursor: pointer;
        text-decoration: none;
    }
    .move-to-top:hover {
        background-color: #212121;
        color: #fff;
    }
    .legend{
        margin-bottom: 10px;
    }
</style>
</head>
<body>

<div class="container">
    <div class="content">
        <h1>HHD-Ethiopic A Historical Handwritten Dataset for Ethiopic OCR with Baseline Models and Human-level Performance</h1>

        <hr>

        <!-- <h2>Scores</h2>
        <table>
            <tr>
                <td><strong>Paper Quality Score:</strong></td>
                <td><span class="score-label score-blue">0.43</span></td>
            </tr>
            <tr>
                <td><strong>LLM Accuracy:</strong></td>
                <td><span class="score-label score-purple">0.47</span></td>
            </tr>
        </table>

        <hr> -->

        <h2>Review Summary</h2>
        <div>
            <span class="legend score-label score-green">&nbsp; &nbsp;</span> The LLM found no significant concern
            <br>
            <span class="legend score-label score-orange">&nbsp; &nbsp;</span> The LLM proposes possible improvements
        </div>
        <table>
            <tr>
              <th>Question</th>
              <th></th>
            </tr>
            
            <tr id="summary-question-1">
                <td>1. Claims</td>
                <td><a href="#question-1" class="scroll-button button-orange">Detailed Review</a></td>
                </tr>
            
            <tr id="summary-question-2">
                <td>2. Limitations</td>
                <td><a href="#question-2" class="scroll-button button-orange">Detailed Review</a></td>
                </tr>
            
            <tr id="summary-question-3">
                <td>3. Theoritical assumptions and proofs</td>
                <td><a href="#question-3" class="scroll-button button-orange">Detailed Review</a></td>
                </tr>
            
            <tr id="summary-question-4">
                <td>4. Experiments reproducibility</td>
                <td><a href="#question-4" class="scroll-button button-orange">Detailed Review</a></td>
                </tr>
            
            <tr id="summary-question-5">
                <td>5. Code and data accessibility</td>
                <td><a href="#question-5" class="scroll-button button-green">Detailed Review</a></td>
                </tr>
            
            <tr id="summary-question-6">
                <td>6. Experimental settings/details</td>
                <td><a href="#question-6" class="scroll-button button-orange">Detailed Review</a></td>
                </tr>
            
            <tr id="summary-question-7">
                <td>7. Error bars</td>
                <td><a href="#question-7" class="scroll-button button-orange">Detailed Review</a></td>
                </tr>
            
            <tr id="summary-question-8">
                <td>8. Compute resources</td>
                <td><a href="#question-8" class="scroll-button button-orange">Detailed Review</a></td>
                </tr>
            
            <tr id="summary-question-9">
                <td>9. NeurIPS code of ethics</td>
                <td><a href="#question-9" class="scroll-button button-orange">Detailed Review</a></td>
                </tr>
            
            <tr id="summary-question-10">
                <td>10. Impacts</td>
                <td><a href="#question-10" class="scroll-button button-orange">Detailed Review</a></td>
                </tr>
            
            <tr id="summary-question-11">
                <td>11. Safeguards</td>
                <td><a href="#question-11" class="scroll-button button-orange">Detailed Review</a></td>
                </tr>
            
            <tr id="summary-question-12">
                <td>12. Credits</td>
                <td><a href="#question-12" class="scroll-button button-orange">Detailed Review</a></td>
                </tr>
            
            <tr id="summary-question-13">
                <td>13. Documentation</td>
                <td><a href="#question-13" class="scroll-button button-orange">Detailed Review</a></td>
                </tr>
            
            <tr id="summary-question-14">
                <td>14. Human subjects</td>
                <td><a href="#question-14" class="scroll-button button-orange">Detailed Review</a></td>
                </tr>
            
            <tr id="summary-question-15">
                <td>15. Risks</td>
                <td><a href="#question-15" class="scroll-button button-orange">Detailed Review</a></td>
                </tr>
            
        </table>

        <!-- Survey -->
        <div>
            <p>After reading through the LLM’s response below, <strong>please complete the following survey about your experience:</strong></p>
            <a class="button" href="https://docs.google.com/forms/d/e/1FAIpQLScr4fjvUGhtiTzBfsqm5CCVvAGafp3sLSSB_Txz2YHhnLiiyw/viewform?usp=pp_url&entry.1830873891=SEhELUV0aGlvcGljIEEgSGlzdG9yaWNhbCBIYW5kd3JpdHRlbiBEYXRhc2V0IGZvciBFdGhpb3BpYyBPQ1Igd2l0aCBCYXNlbGluZSBNb2RlbHMgYW5kIEh1bWFuLWxldmVsIFBlcmZvcm1hbmNl" target="_blank">Click to submit post submission survey</a>
            <p>Your feedback is critical to evaluate the effectiveness of this LLM checklist assistant!</p>
        </div>

        <hr>

        <h2>Detailed Review</h2>
        
        
        <div class="review" id="question-1">
            <div class="user_input">
                <p><strong class="question">Question # 1:</strong> Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope?</p>
                <p><strong class="answer">Author's answer:</strong> Yes</p>
                <p><strong class="justification">Author's justification:</strong> We provide a list of contributions in the introduction that describes well our contributions. Additionally, the abstract summarizes well the paper as a whole.</p>
            </div>
            
            <div class="llm_review llm_review-orange "><strong>LLM Review:</strong><br> The abstract and introduction make broad claims about advancements in multi-objective hyperparameter optimization (MOHPO) and the presentation of a novel dataset, HHD-Ethiopic. However, while the paper details the development of a multi-objective Bayesian optimization (MoBO) algorithm and its application to OCR models, the abstract mentions machine learning hyperparameter optimization in a general context without explicitly making the connection to its application in OCR, particularly for the Ethiopic script. Moreover, the transition from discussing generalized MOHPO challenges to introducing a historical handwritten dataset for the Ethiopic script is abrupt and lacks cohesion. The paper's title suggests a focus on the HHD-Ethiopic dataset for OCR, but the abstract and introduction cover broader MOHPO advancements without directly tying these to the OCR application until much later sections.<br>Feedback:<ol><li> Clarify the connection between MOHPO advancements and their application to OCR in both the abstract and introduction. Explicitly state how the proposed MoBO algorithm benefits the specific OCR tasks, especially for low-resource scripts like Ethiopic.</li><li> Provide a smoother transition from discussing general hyperparameter optimization challenges to introducing the HHD-Ethiopic dataset and its relevance. Connect these sections by highlighting the importance of the dataset in addressing the specific challenges of OCR for Ethiopic scripts.</li><li> The paper should explicitly mention the novel contributions relating to the HHD-Ethiopic dataset early in the introduction, including its significance for OCR research in underrepresented languages.</li><li> Ensure the abstract balances the description of both MOHPO algorithmic contributions and the introduction of the HHD-Ethiopic dataset. Both are major contributions, but their representation in the abstract and introduction appears disjointed.</li><li> Revise the title if necessary to more accurately reflect the dual focus on MOHPO and the Ethiopic OCR dataset, ensuring it captures the essence of both significant contributions.</li><br><br></ol></div>
            <a class="move-to-top" href="#summary-question-1">↑ Back to summary</a>
        </div>
        
        <div class="review" id="question-2">
            <div class="user_input">
                <p><strong class="question">Question # 2:</strong> Does the paper discuss the limitations of the work performed by the authors?</p>
                <p><strong class="answer">Author's answer:</strong> Yes</p>
                <p><strong class="justification">Author's justification:</strong> We acknowledged in the annotation process that some annotators anonymously shared information, despite our efforts to ensure data confidentiality. Additionally, we acknowledge that our limited computational resources did not allow us to conduct extensive experiments. We also indicate some future work in the conclusion.</p>
            </div>
            
            <div class="llm_review llm_review-orange "><strong>LLM Review:</strong><br> The authors' answer to the question about discussing the limitations of the work performed is generally in alignment with what is expected in NeurIPS conference submissions. However, the authors' justification for their answer points out specific instances mentioned in the paper without giving precise section references where these discussions can be found. This lack of specificity makes it challenging to verify the claims directly.<br><h3>Actionable Feedback</h3><br><ol><li> <b>Specific Section References</b>: The authors should modify the justification to include specific section numbers or titles where the limitations are discussed. For instance, instead of stating "We acknowledged in the annotation process," they could rephrase it to "In Section 3.1 (Dataset and Baseline Methods), we discuss limitations concerning the annotation process..."</li><br><li> <b>Broadening Limitations Discussion</b>: While the answer points to computational resources and annotator challenges, the paper could benefit from a more extensive discussion on limitations. This includes reflecting on the machine learning model's performance across different test settings, robustness to dataset biases, and generalizability to unseen data, potentially in a designated "Limitations" section as recommended.</li><br><li> <b>Clarity on Future Work</b>: While mentioning future work in the conclusion is good, distinguishing clearly between limitations of the current work and areas for future exploration could enhance the paper's quality. Different subsections for "Limitations" and "Future Work" within the conclusion section could be beneficial.</li><br><li> <b>Assumptions and Their Impact</b>: The paper should articulate any assumptions made during the development of the machine learning models and discuss how violations of these assumptions might affect the results. This is especially important given the dataset's unique characteristics and the potential variance in OCR performance across scripts.</li><br><li> <b>Include Discussion on Data Privacy and Fairness</b>: If the dataset includes or potentially impacts individual privacy or introduces bias, these aspects need to be addressed directly in the paper.</li><br><li> <b>Enhance Discussion on Computational Efficiency</b>: If computational limitations were a significant challenge, the paper could benefit from a more nuanced discussion on how these limitations impacted the approach or results and potential pathways to mitigate these limitations in future work.</li><br><li> <b>Transparency and Reproducibility</b>: Ensuring that the discussion on limitations aids in the transparency and reproducibility of the research. If certain experiments could not be performed due to the stated limitations, explicitly stating so helps set the right expectations.</li><br></ol>By addressing these points, the authors can significantly improve the paper's quality, contributing to a more transparent and constructive scientific dialogue within the community.<br><ol><li>5</li></ol></div>
            <a class="move-to-top" href="#summary-question-2">↑ Back to summary</a>
        </div>
        
        <div class="review" id="question-3">
            <div class="user_input">
                <p><strong class="question">Question # 3:</strong> For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof?</p>
                <p><strong class="answer">Author's answer:</strong> NA</p>
                <p><strong class="justification">Author's justification:</strong> Our paper does not include any theory.</p>
            </div>
            
            <div class="llm_review llm_review-orange "><strong>LLM Review:</strong><br> The author's proposed answer is inconsistent with the content of the paper, which does include theoretical results. Specifically, the paper contains a theorem (Theorem 1) and a corollary (Corollary 1) in Section 4, contradicting the author's claim that their paper does not include any theory. This discrepancy means the appropriate action for the checklist question on theoretical results should be "Yes," and the justification should point to Section 4 where the theorem and its corollary are presented.<br>To align the paper with the guidelines on reporting theoretical results, the following improvements are recommended:<br><ol><li> <b>Update Checklist Response</b>: Change the answer to the checklist question on theoretical results to "Yes," indicating that the paper does contain theoretical contributions.</li><br><li> <b>Provide Full Set of Assumptions</b>: Ensure that all assumptions made for Theorem 1 and its corollary are explicitly stated or referenced in the paper. If these assumptions are spread out in different sections, consider summarizing them in Section 4 for clarity.</li><br><li> <b>Complete and Correct Proof</b>: Confirm that the proof of Theorem 1 and the justification of Corollary 1 are both complete and correct. If the proofs are too lengthy for the main body, include them in an appendix or supplemental material, referencing this clearly in Section 4.</li><br><li> <b>Cross-Reference Theorem and Related Work</b>: The authors should cross-reference Theorem 1 and Corollary 1 within the paper, especially when discussing methodological contributions, results, or comparing with related works. This will highlight the theoretical foundations of their research contributions more thoroughly.</li><br><li> <b>Proof Sketch in Main Body</b>: If the complete proof is moved to an appendix or supplementary material for brevity, consider providing a short proof sketch in Section 4. This would offer readers a clearer understanding of the theorem’s implications and its significance to the paper's contributions.</li><br><li> <b>Reference Theorems and Lemmas</b>: Properly reference any external theorems, lemmas, or foundational works that Theorem 1 and Corollary 1 rely upon. This step is crucial for situating the paper within the broader research landscape and ensuring the originality and contribution of the theoretical aspects.</li><br></ol>Incorporating these improvements will ensure compliance with the checklist guidelines, enhance the clarity and integrity of the theoretical contributions, and potentially increase the paper’s impact and acceptance likelihood at the NeurIPS conference.<br></div>
            <a class="move-to-top" href="#summary-question-3">↑ Back to summary</a>
        </div>
        
        <div class="review" id="question-4">
            <div class="user_input">
                <p><strong class="question">Question # 4:</strong> Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)?</p>
                <p><strong class="answer">Author's answer:</strong> Yes</p>
                <p><strong class="justification">Author's justification:</strong> We provide in Section 3.2 the settings for human-level performance and baseline models. In section 4.2 we provide the settings for the Baseline OCR models.</p>
            </div>
            
            <div class="llm_review llm_review-orange "><strong>LLM Review:</strong><br> The proposed answer by the authors suggests that all necessary information for reproducing the key experimental results is disclosed in specific sections of the paper. However, upon closer review against the guidelines for ensuring reproducibility, several areas for improvement emerge:<br><ol><li> <b>Detailed Description of Dataset Processing and Preparation</b>: Although Section 3.1 outlines the characteristics of the HHD-Ethiopic dataset, it may lack comprehensive details on preprocessing steps, such as the specific techniques used for image normalization, resizing, and augmentation if any. Actionable feedback: Authors should provide explicit details on data preprocessing steps to enable exact replication.</li><br><li> <b>Hyperparameter Specifications and Model Configurations</b>: While Sections 3.2 and 4.2 mention settings for human-level performance, baseline OCR models, and the Baseline OCR models, respectively, there may not be sufficient clarity on the exact hyperparameters and configurations used for model training and evaluation. Actionable feedback: Authors should list hyperparameters (e.g., learning rate, batch size, epochs) and any model-specific settings to ensure clarity.</li><br><li> <b>Evaluation Metrics and Statistical Measures</b>: For replicating and validating experimental results, it's critical to understand how results were evaluated and the statistical methods used to ensure findings' validity. While human-level performance and baseline comparisons are discussed, explicit mention of evaluation metrics (e.g., Character Error Rate, Word Error Rate) and any statistical tests or confidence intervals used would enhance reproducibility. Actionable feedback: Specify all evaluation metrics used and provide justification for their choice, along with any statistical methods applied to analyze the experiment results.</li><br><li> <b>Software and Hardware Environment</b>: Reproducing experimental results may also depend on the computational environment, including software versions (e.g., machine learning libraries, languages) and hardware specifications. Actionable feedback: Include a section on the software (with versions) and hardware used to conduct experiments to aid in replicating the setup.</li><br><li> <b>Accessibility of Training, Validation, and Test Sets</b>: The paper mentions the availability of the dataset and codebase, which is commendable. However, ensuring that splits of data (training, validation, test sets) are clearly defined and accessible is crucial for reproductions. Actionable feedback: Ensure the dataset splits used in experiments are publicly accessible or clearly documented in the repository linked, including any specific instructions for generating dataset splits if applicable.</li><br><li> <b>License and Use Permissions</b>: For datasets and code, clarity on licensing and use permissions facilitates reproducibility and future research. Actionable feedback: Specify the license under which the dataset and code are released and any restrictions on their use.</li><br></ol><b>Concluding with a score considering the guidance provided and the checklist for ensuring experimental reproducibility, it appears there may be room for improvement in detailing and explicitly documenting experimental procedures, configurations, and environments.</b><br><br></div>
            <a class="move-to-top" href="#summary-question-4">↑ Back to summary</a>
        </div>
        
        <div class="review" id="question-5">
            <div class="user_input">
                <p><strong class="question">Question # 5:</strong> Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material?</p>
                <p><strong class="answer">Author's answer:</strong> Yes</p>
                <p><strong class="justification">Author's justification:</strong> We provide the description about the dataset and the open-source implementation details at https://github.com/ethopic/hhd-ethiopic-I. Users can reproduce the results by following the information provided at this link. Furthermore, detailed information about the Ethiopic writing system and data collection procedures can be found in the appendix section of this paper. In addition, the dataset datasheet is provided as supplementary material.</p>
            </div>
            
            <div class="llm_review llm_review-green "><strong>LLM Review:</strong><br> Itemized, actionable feedback for paper quality improvement:<br><ol><li> Ensure the repository URL provided (https://github.com/ethopic/hhd-ethiopic-I) is accessible and contains all necessary data and code as claimed. Verify that the link is not broken and contents are properly organized for ease of access.</li><br><li> Provide explicit, step-by-step instructions in the repository README for reproducing the main experimental results, including environment setup (e.g., required libraries with versions), data preprocessing steps, and the exact commands to run the experiments.</li><br><li> Include a requirements.txt file or an environment.yml file in the repository for setting up the exact software environment used in the experiments. This will help in replicating the environment quickly and accurately.</li><br><li> Clarify which parts of the experiments (if any) cannot be reproduced with the provided data and code. If certain results rely on proprietary or inaccessible data, or computationally prohibitive processes, explicitly state this in the paper and the repository README.</li><br><li> If not already included, add comments within the code to explain the purpose of each script and function, making it easier for others to understand and modify the code for their own experiments.</li><br><li> Ensure the dataset datasheet provided as supplementary material contains comprehensive information about the dataset, including details on collection processes, ethical considerations, data distribution, and usage restrictions if any.</li><br><li> Address data licensing issues by stating the license under which the dataset and code are released. Make it clear whether there are any restrictions on the use of the data or code, especially for commercial purposes.</li><br><li> Verify that all figures, tables, and supplementary materials mentioned in the paper and justified for this checklist question are properly included and accurately referenced in the paper. Ensure these materials are clearly labeled and easy to navigate.</li><br><li> Finally, actively maintain the repository to respond to issues or questions from users attempting to replicate the results. Community engagement can highlight unforeseen issues and contribute to the integrity of the research.</li><br><br></ol></div>
            <a class="move-to-top" href="#summary-question-5">↑ Back to summary</a>
        </div>
        
        <div class="review" id="question-6">
            <div class="user_input">
                <p><strong class="question">Question # 6:</strong> Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results?</p>
                <p><strong class="answer">Author's answer:</strong> Yes</p>
                <p><strong class="justification">Author's justification:</strong> All the details are provided in Section 4.2.</p>
            </div>
            
            <div class="llm_review llm_review-orange "><strong>LLM Review:</strong><br> The proposed author's "Answer" indicates that all necessary training and test details are specified in Section 4.2 of the paper. Based on the provided text, there seems to be a discrepancy in the reported Section and the content description related to the experimental setup or model training details. The text outlines the dataset constitution and models used for OCR in Section 3 titled "Dataset and baseline methods," not Section 4.2. This section is more aligned with what would be expected for providing sufficient details on training and testing specifications necessary for understanding the results according to the checklist question.<br><h3>Actionable feedback:</h3><br><ol><li> <b>Correct Section Reference</b>: The authors should correct the section reference in their "Justification" to accurately indicate where the training and testing details can be found. If Section 4.2 was mentioned erroneously, it should be amended to the correct section (Section 3 based on the paper description provided).</li><br><li> <b>Comprehensive Training Detail Description</b>: Ensure that Section 3 (or the correctly referenced section) includes detailed descriptions of:</li></ol>- Data preprocessing steps.- Split ratios for training and testing datasets alongside the rationale for their selection.- Hyperparameter selection methodology, including any hyperparameter tuning or optimization performed.- Specifics of the optimizer used and the reasoning behind its choice.<br><ol><li> <b>Inclusion of Test Details</b>: Confirm that the mentioned section details the test environments, including any specific settings employed during model evaluation, such as evaluation metrics, thresholds for success criteria, and hardware configurations if significant for replicating the experiments.</li><br><li> <b>Clarity on Model Configuration</b>: Provide explicit details on the baseline OCR models including architectural nuances, versioning (if leveraging pre-existing models), and any modifications made to adapt them for the task at hand.</li><br><li> <b>Supplementary Material Reference</b>: If any training detail deemed essential for result replication exceeds the space limitations of the main paper body, consider including it as supplementary material or in an appendix. Ensure that the reference to such supplementary content is clearly stated within the section addressing the training and testing methodologies.</li><br><li> <b>Transparency on Data Division</b>: Clarify the method used for dividing the dataset into training and test sets ensuring it aligns with standard practices to avoid bias, and explain any stratification or specific considerations made due to the data's nature.</li><br></ol>By addressing these points, the authors will significantly improve the clarity and reproducibility of their experimental setup, enabling peers to better understand and potentially replicate the study's outcomes.<br></div>
            <a class="move-to-top" href="#summary-question-6">↑ Back to summary</a>
        </div>
        
        <div class="review" id="question-7">
            <div class="user_input">
                <p><strong class="question">Question # 7:</strong> Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments?</p>
                <p><strong class="answer">Author's answer:</strong> Yes</p>
                <p><strong class="justification">Author's justification:</strong> We provide box-whiskers plots in Figure 5.</p>
            </div>
            
            <div class="llm_review llm_review-orange "><strong>LLM Review:</strong><br> The provided "Answer" aligns with the "Guidelines" in that it affirms the inclusion of statistical error reporting (specifically mentioning box-whiskers plots in Figure 5). However, the "Justification" only partially adheres to the comprehensive expectations set by the "Guidelines". Specifically, it fails to detail:<br><ol><li> The factors of variability the error bars capture.</li><li> The method for calculating the error bars.</li><li> The assumptions made (e.g., normality of errors).</li><li> Whether the error bar represents the standard deviation, the standard error of the mean, or a confidence interval, and if it's the latter, whether it is a 1-sigma or 2-sigma error bar equivalent.</li><br></ol><b>Feedback to Improve Paper Quality</b><br><ol><li> <b>Explain Variability Factors:</b> Explicitly state what factors of variability are accounted for by the error bars in Figure 5 (e.g., initialization, random drawing of some parameter).</li><br><li> <b>Methodology Description:</b> Provide a clear description or reference to the method used for calculating the error bars (e.g., bootstrap, library function, etc.) in either the figure caption or the relevant results section of the text.</li><br><li> <b>Assumptions Disclosure:</b> Disclose any assumptions made during error bar calculations (e.g., assuming normally distributed errors). This is critical for the scientific rigour of the paper.</li><br><li> <b>Clarify Error Bar Type:</b> Clearly specify whether the error bars denote standard deviations, standard errors of the mean, or confidence intervals. If claiming a particular confidence interval, verify the underlying distribution assumptions or opt for non-parametric intervals.</li><br><li> <b>Data Representation:</b> When presenting asymmetric distributions in the results, ensure that the error bars correctly represent the distribution range to avoid implying impossible values (e.g., negative rates).</li><br><li> <b>Textual Explanation:</b> Augment the visual representation in Figure 5 with a textual explanation of how the error bars were calculated. This provides clarity for readers who might not be as visually inclined or familiar with box-whisker plot conventions.</li><br><li> <b>Reference in Text:</b> Increase the paper's readability by explicitly referencing Figure 5 and its error bars in the relevant sections discussing experimental results or statistical significance, allowing readers to easily locate the related information.</li><br></ol>Incorporating this feedback will markedly improve the paper’s alignment with conference expectations regarding statistical reporting, enhancing its clarity, accuracy, and credibility.<br></div>
            <a class="move-to-top" href="#summary-question-7">↑ Back to summary</a>
        </div>
        
        <div class="review" id="question-8">
            <div class="user_input">
                <p><strong class="question">Question # 8:</strong> For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments?</p>
                <p><strong class="answer">Author's answer:</strong> Yes</p>
                <p><strong class="justification">Author's justification:</strong> All details are provided in the experimental section.</p>
            </div>
            
            <div class="llm_review llm_review-orange "><strong>LLM Review:</strong><br> The proposed author's "Answer" claims that all necessary details on the computer resources needed to reproduce the experiments are provided in the experimental section of the paper. However, a thorough examination of the paper reveals that specific details regarding computer resources such as type of compute workers (CPU or GPU), the exact model or specifications of these workers, memory, storage, execution time, and whether the resources were part of an internal cluster or cloud provider are missing. The paper does not disclose the amount of compute required for individual experimental runs or estimate the total compute, nor does it mention if additional compute was necessary beyond what was reported for the experiments.<br><b>Feedback:</b><br><ol><li> <b>Specify Compute Workers</b>: Clearly identify whether CPUs or GPUs were used for the experiments. Include the exact model or configuration of these workers. If both types were used, detail the tasks each type was assigned.</li><br><li> <b>Memory and Storage Details</b>: Provide information on the memory and storage capacities utilized during the experimental runs. This is crucial for accurately reproducing the study, especially for resource-intensive tasks.</li><br><li> <b>Execution Time</b>: Include detailed execution times for each experimental run. This gives an indication of the computational effort involved and allows for the comparison of efficiency with future methods.</li><br><li> <b>Computing Environment</b>: Clarify whether an internal cluster, cloud provider, or standalone systems were used. The choice of environment can significantly impact the reproducibility of the results, given variations in performance and resource availability.</li><br><li> <b>Quantify Compute Requirements</b>: Estimate the amount of compute (in GPU-hours or CPU-hours) required for each experimental run. Providing a total compute estimate helps in planning the resources needed for replication attempts.</li><br><li> <b>Disclosure of Resource Overheads</b>: Disclose if the full research project required additional compute resources beyond what was used for the reported experiments. This includes preliminary tests, model development iterations, and failed experiments, which are often necessary for understanding the scope of resource commitments.</li><br></ol>Incorporating these detailed specifications into the experimental section will significantly improve the reproducibility of the research and align the paper with the NeurIPS guidelines for completeness and transparency in reporting experimental methodologies.<br></div>
            <a class="move-to-top" href="#summary-question-8">↑ Back to summary</a>
        </div>
        
        <div class="review" id="question-9">
            <div class="user_input">
                <p><strong class="question">Question # 9:</strong> Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?</p>
                <p><strong class="answer">Author's answer:</strong> Yes</p>
                <p><strong class="justification">Author's justification:</strong> The workers hired were compensated.</p>
            </div>
            
            <div class="llm_review llm_review-orange "><strong>LLM Review:</strong><br> The Authors' Proposed Answer to the checklist question regarding adherence to the NeurIPS Code of Ethics is overly simplistic and does not sufficiently address the broad scope of ethical considerations outlined by NeurIPS. The justification provided, focusing solely on worker compensation, fails to encompass other essential aspects of ethical research considerations such as data privacy, potential misuses of research, fairness, transparency, accountability, and societal impact.<br><b>Feedback for Improvement:</b><br><ol><li> <b>Comprehensive Ethical Considerations:</b> Expand the justification to include other relevant ethical aspects such as data privacy (how the data was collected and if consent was obtained), potential for misuse of the research findings, measures taken to ensure fairness and reduce bias in models, and transparency in model development and dataset creation.</li><br><li> <b>Data Sources and Privacy:</b> Clarify in the paper the origins of the dataset used, ensuring that it was ethically sourced. If the data involves human subjects or potentially sensitive information, describe the consent process and any anonymization techniques employed to protect individuals' privacy.</li><br><li> <b>Fairness and Bias Mitigation:</b> Discuss any efforts made to identify and mitigate biases in the dataset and the models. This may include analysis of model performance across different subgroups or efforts to ensure the dataset is representative.</li><br><li> <b>Transparency and Reproducibility:</b> Ensure transparency by clearly describing the experimental setup, data preparation, and model development processes. Offer access to the codebase, pre-trained models, and detailed documentation to enable reproducibility.</li><br><li> <b>Societal Impact and Potential Misuse:</b> Outline the potential societal impacts of your research, both positive and negative. Discuss any measures taken to mitigate the risks of misuse of your technology, especially if it could be employed in ways that might infringe on privacy rights or be used for surveillance without consent.</li><br><li> <b>Compliance with Local Regulations:</b> If there are local laws or regulations concerning data collection, processing, or the deployment of machine learning models, discuss how your research complies with these norms.</li><br><li> <b>Accessibility and Inclusivity:</b> Mention efforts to ensure the research benefits a wide audience and how it promotes inclusivity, especially if it involves languages or scripts that are underrepresented in computational research.</li><br></ol>Adding these details will not only strengthen the ethical considerations section of your paper but will also highlight the thoroughness of your research process and your commitment to responsible AI development.<br></div>
            <a class="move-to-top" href="#summary-question-9">↑ Back to summary</a>
        </div>
        
        <div class="review" id="question-10">
            <div class="user_input">
                <p><strong class="question">Question # 10:</strong> Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed?</p>
                <p><strong class="answer">Author's answer:</strong> Yes</p>
                <p><strong class="justification">Author's justification:</strong> All potential impact is positive.</p>
            </div>
            
            <div class="llm_review llm_review-orange "><strong>LLM Review:</strong><br> The authors' answer indicates a discrepancy with the expectation set by the guidelines. While the authors confidently claim all potential impacts are positive, the guidelines clearly mandate discussions on both potential positive and negative societal impacts of the work.<br><b>Actionable Feedback:</b><br><ol><li> <b>Revise Societal Impact Section</b>: Amend the societal impact section to include a balanced discussion that not only highlights the positive impacts, such as advancements in OCR for underrepresented languages, facilitating access to cultural and historical documents but also addresses potential negative impacts. This could include misuse of the technology, biases in OCR performance across different Ethiopic scripts, or cultural and linguistic preservation vs. digital distortion concerns.</li><br><li> <b>Reference Specific Sections</b>: Ensure the revised discussion on societal impacts refers to explicit sections where these impacts are elaborated. This conformity to guidelines will increase the paper’s credibility and adherence to conference expectations.</li><br><li> <b>Consider Ethical Implications</b>: Elaborate on ethical implications related to the use of historical data, including privacy concerns, the potential for misrepresentation of cultural materials, and how your work mitigates such risks.</li><br><li> <b>Mitigation Strategies for Negative Impacts</b>: Besides identifying negative impacts, propose potential mitigation strategies. This could involve technical solutions, ethical guidelines for use, or collaboration with cultural experts to ensure respectful and accurate application of the technology.</li><br><li> <b>Broader Societal Implications</b>: Broaden the discussion to include impacts on non-technical stakeholders, such as historians, linguists, and cultural heritage professionals. Specify how this work benefits these groups and any possible risks or challenges they might face.</li><br><li> <b>Update Abstract and Conclusion</b>: Reflect the addition of societal impact discussions in both the abstract and the conclusion for consistency and to guide readers' expectations correctly about the paper’s content.</li><br><li> <b>Public Dataset and Model Considerations</b>: If applicable, discuss the implications of making the dataset and models publicly available, including positive aspects like promoting research in underrepresented language processing and potential concerns related to privacy or misuse.</li><br></ol>By addressing these points, the paper will not only meet the NeurIPS conference guidelines more closely but also contribute to a more responsible and holistic presentation of technological research impacts.<br></div>
            <a class="move-to-top" href="#summary-question-10">↑ Back to summary</a>
        </div>
        
        <div class="review" id="question-11">
            <div class="user_input">
                <p><strong class="question">Question # 11:</strong> Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)?</p>
                <p><strong class="answer">Author's answer:</strong> NA</p>
                <p><strong class="justification">Author's justification:</strong> There are no LLMs or GenAI in this paper.</p>
            </div>
            
            <div class="llm_review llm_review-orange "><strong>LLM Review:</strong><br> The authors' response that the question is not applicable (NA) because their paper does not involve LLMs or GenAI may overlook datasets' potential misuse. Their paper introduces a newly created HHD-Ethiopic dataset for Ethiopic OCR, which could pose risks due to the sensitive nature of historical documents and the potential for misuse of OCR technology. Given this context, their justification appears insufficient, particularly when considering the guidelines on responsible data release outlined by NeurIPS.<br>Actionable feedback for improvement includes:<br><ol><li> <b>Reevaluate Risks for Misuse</b>: Reassess the dataset and OCR models' potential risks for misuse, considering access to and use of historical documents. This reassessment should be explicitly documented in the paper, possibly in the dataset description section.</li><br><li> <b>Provision of Safeguards</b>: If any potential risks are identified, describe the safeguards put in place to mitigate these risks. This could involve access restrictions, ethical guidelines for use, or data anonymization processes, among others.</li><br><li> <b>Explicit Statement on Ethical Considerations</b>: Even if the authors firmly believe that their work has no misuse potential, including a brief statement on ethical considerations undertaken during dataset creation and model development would strengthen the paper. This could cover the consent process for data collection and the intended fair use of the dataset and models.</li><br><li> <b>Consultation with Ethical Bodies or Guidelines</b>: If not already done, consulting with an ethical review board or following established ethical guidelines for dataset creation and usage in AI research can be beneficial. Mention of such consultations can add credibility to the authors' claim of responsible research practices.</li><br><li> <b>Community and Future Work Considerations</b>: Discuss the implications of the dataset and models for the broader research community and any measures to ensure positive impact. This may also involve outlining future work to address any unresolved ethical or misuse concerns.</li><br></ol>Considering the importance of responsible AI research and the explicit guidelines by NeurIPS, addressing these points could substantially improve the paper's alignment with ethical standards and community expectations.<br><br></div>
            <a class="move-to-top" href="#summary-question-11">↑ Back to summary</a>
        </div>
        
        <div class="review" id="question-12">
            <div class="user_input">
                <p><strong class="question">Question # 12:</strong> Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected?</p>
                <p><strong class="answer">Author's answer:</strong> Yes</p>
                <p><strong class="justification">Author's justification:</strong> A datasheet for dataset was provided with all license information.</p>
            </div>
            
            <div class="llm_review llm_review-orange "><strong>LLM Review:</strong><br> The proposed author's "Answer" indicates a positive outcome regarding the crediting of asset creators and proper mention of licenses and terms of use, justified by the provision of a datasheet for the dataset containing all license information. However, the justification lacks specific details regarding the crediting of other assets like code or models used in the research, if any, and does not specify the section(s) within the paper where this information can be found. This leads to a discrepancy between the provided "Justification" and the "Guidelines" which require pointing to specific section(s) where related materials for the question can be found, including the crediting of all assets used, not just datasets.<br><h3>Actionable Feedback:</h3><br><ol><li> <b>Explicitly Credit All Assets Used:</b> Ensure that all assets such as models, code libraries, or other datasets used in the study, beyond the HHD-Ethiopic dataset, are clearly credited. Mention the creators or original owners of these assets explicitly.</li><br><li> <b>Specify License Information for Each Asset:</b> Detail the license information for all used assets, including the type of licenses (e.g., MIT, GPL, CC-BY) and any terms of use. If different assets have different licenses, specify this information separately for each.</li><br><li> <b>Provide Direct References in the Paper:</b> The answer should be improved by directly referencing the section(s) of the paper where the crediting of assets and the license information is provided. If this information is spread across multiple sections, each relevant section should be mentioned explicitly. If not already present in the paper, add a subsection or section dedicated to Data and Asset Licensing, including URLs to repositories or data sources when possible.</li><br><li> <b>Include a Discussion on Data and Code Availability:</b> If the paper makes use of proprietary or restricted-access data, or if there are any limitations on the availability of the developed code or models, discuss these explicitly. This discussion can be part of the methodology section or a separate Data/Code Availability section.</li><br><li> <b>Address Data Scraping and Copyright Concerns:</b> If any data were scraped from websites or digital libraries, ensure to mention the copyright and terms of service of the source, and how they align with your use of the data. Describe the process taken to ensure compliance with these terms.</li><br><li> <b>Improve the Dataset Datasheet:</b> Ensure the datasheet for the HHD-Ethiopic dataset is comprehensive, detailing the creation process, character distribution, any synthetic data generation methods, and ethical considerations. This can address both the transparency and reproducibility aspects of the research.</li><br><li> <b>Ensure Accessibility and Openness with a DOI:</b> For the dataset and any developed software, ensure accessibility by providing a DOI (Digital Object Identifier) where applicable, and state this clearly in the paper.</li><br></ol>Incorporating this feedback will not only align the paper with NeurIPS guidelines but also enhance its overall transparency, reproducibility, and ethical adherence to open science practices.<br></div>
            <a class="move-to-top" href="#summary-question-12">↑ Back to summary</a>
        </div>
        
        <div class="review" id="question-13">
            <div class="user_input">
                <p><strong class="question">Question # 13:</strong> Are new assets introduced in the paper well documented and is the documentation provided alongside the assets?</p>
                <p><strong class="answer">Author's answer:</strong> Yes</p>
                <p><strong class="justification">Author's justification:</strong> We provide details in appendix and in the datasheet for datasets.</p>
            </div>
            
            <div class="llm_review llm_review-orange "><strong>LLM Review:</strong><br> The provided justification mentions the location of the details and datasheet for datasets, but does not explicitly verify the completeness and depth of the documentation regarding the newly introduced assets, particularly in compliance with the guidelines' specifics on training details, license, limitations, and how consent was obtained for asset use. Considering the guidelines provided for NeurIPS submissions concerning assets documentation, the following improvements are recommended for the paper:<br><ol><li> <b>Detailed Training Information</b>: The paper should include precise details about the training process for models developed using the HHD-Ethiopic dataset. This includes hyperparameters settings, training-validation split, preprocessing techniques, and any data augmentation employed.</li><br><li> <b>Licensing Information</b>: Adding explicit information about the dataset's licensing is crucial. It guides potential users on how they can legally use the dataset and any derivative works or models. If the dataset is under a specific license, stating which license and providing its summary or implications can significantly improve the dataset's utility and adherence to open science principles.</li><br><li> <b>Limitations Disclosure</b>: While the dataset constitutes a valuable resource for the Ethiopic OCR task, any limitations regarding its representation of the language, time periods covered, manuscript conditions, or biases in character or word frequencies should be explicitly documented. This transparency helps future researchers understand the context and limitations when utilizing the dataset for their experiments.</li><br><li> <b>Consent and Ethical Considerations</b>: Given the dataset's historical nature, detailing how consent was obtained (if applicable) might not be straightforward. However, covering any ethical considerations involved in digitizing and using these manuscripts for research purposes, including but not limited to cultural sensitivity and rights to digital representation, would enhance the paper's ethical rigor.</li><br><li> <b>Anonymization Process</b>: If any part of the data collection or preparation process involved modern contributors (e.g., transcribers or annotators), the paper should describe how their privacy was protected, ensuring compliance with GDPR or similar regulations.</li><br><li> <b>Accessibility and Reproducibility</b>: Ensuring that the dataset and related assets (e.g., trained models, code for baseline methods) are easily accessible and usable by others is paramount. This includes providing a clear, anonymized URL if the assets are hosted online, ensuring that the link is functional and that any required access permissions are clearly stated.</li><br></ol>To make these improvements actionable, the authors should revise their paper and supplementary materials to address these points specifically. It is also advised to include examples of use-cases or previous research utilizing the dataset (if any) to illustrate its value and applications further. Such revisions would enhance the paper's contribution to the community by providing a well-documented resource for advancing OCR technologies, especially for underrepresented scripts.<br></div>
            <a class="move-to-top" href="#summary-question-13">↑ Back to summary</a>
        </div>
        
        <div class="review" id="question-14">
            <div class="user_input">
                <p><strong class="question">Question # 14:</strong> For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)?</p>
                <p><strong class="answer">Author's answer:</strong> NA</p>
                <p><strong class="justification">Author's justification:</strong> There were no crowdsourcing experiments conducted.</p>
            </div>
            
            <div class="llm_review llm_review-orange "><strong>LLM Review:</strong><br> The author's proposed answer to the checklist question is "NA" with the justification that there were no crowdsourcing experiments conducted. Given the content of the paper titled "HHD-Ethiopic A Historical Handwritten Dataset for Ethiopic OCR with Baseline Models and Human-level Performance," the focus is primarily on the development and evaluation of a machine learning framework and dataset for recognizing Ethiopic script in handwritten documents. The paper outlines the dataset's creation, characteristics, and the methods for building and assessing OCR models, including comparisons with human-level performance. No mention or indication of crowdsourcing experiments or research involving human subjects, in the sense of data collection from a crowd via platforms like Mechanical Turk or similar, is noted in the summary provided. However, the paper does discuss human involvement in the dataset creation and evaluation process.<br>Given the details provided and adhering strictly to the guidelines and the context of the checklist question, the authors' response appears aligned with the paper content regarding the specific aspect of crowdsourcing. However, there is a significant involvement of human participants in creating and evaluating the dataset, which broadly falls under research with human subjects. This raises a nuanced interpretation of the checklist question, possibly requiring clarification or expansion regarding what constitutes "research with human subjects" beyond conventional crowdsourcing models.<br><b>Actionable Feedback:</b><br><ol><li> <b>Clarify Involvement of Human Participants:</b> Although not technically crowdsourcing, the paper involves human subjects in data annotation and evaluation. The authors should consider providing more detailed information about the recruitment, consent process (if any), and compensation for these participants, to align with ethical research practices, even if the primary activity is not labeled as crowdsourcing.</li><br><li> <b>Expand on Ethical Considerations:</b> Given the involvement of high school students in data annotation, a discussion on ethical considerations, including parental consent, participant privacy, and data protection measures, would enhance the paper's adherence to ethical standards in research involving human subjects.</li><br><li> <b>Detail Compensation Structure:</b> If the participatory individuals (e.g., annotators and reviewers) received any form of compensation, acknowledgment, or incentives, detailing this would provide transparency and adhere to guidelines about compensation disclosure in research involving human labor.</li><br><li> <b>Include Participant Demographic Breakdown:</b> Offering a demographic breakdown and mentioning any diversity considerations or limitations in the participant pool could add value to the dataset's representation and utility discussion.</li><br><li> <b>Provide Access to Consent Forms or Guidelines:</b> If applicable, making the consent forms or participant instruction guidelines available as part of the supplementary materials could offer insights into the ethical framing and participant briefing process of the study.</li><br></ol></div>
            <a class="move-to-top" href="#summary-question-14">↑ Back to summary</a>
        </div>
        
        <div class="review" id="question-15">
            <div class="user_input">
                <p><strong class="question">Question # 15:</strong> Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained?</p>
                <p><strong class="answer">Author's answer:</strong> NA</p>
                <p><strong class="justification">Author's justification:</strong> This is not needed for this work.</p>
            </div>
            
            <div class="llm_review llm_review-orange "><strong>LLM Review:</strong><br> The "NA" answer and the justification provided by the authors indicate a misunderstanding or oversight concerning the involvement of human participants in the creation of the HHD-Ethiopic dataset. The paper detailed extensive involvement of human annotators in the dataset creation and validation process. It mentions the recruitment of participants for dataset annotation, the use of human-level performance as a baseline for model evaluation, and the collection of ground truth data involving human judgment. These activities clearly involve human subjects in the research, and thus, ethical considerations including IRB approval, disclosure of risks to participants, and informed consent processes are relevant and necessary to discuss in the paper.<br><b>Actionable Feedback:</b><br><ol><li> <b>Revise the Answer to Reflect Human Subject Research</b>: Acknowledge the involvement of human participants in the dataset creation and validation sections. The answer to the checklist question should be revised from "NA" to "Yes," indicating the involvement of human subjects in the research.</li><br><li> <b>Disclose Participant Involvement and Ethical Considerations</b>: Detail the process of participant recruitment, the nature of their involvement, any risks or burdens posed by the participation, and how these were communicated to the participants. If any benefits were offered (e.g., educational), this should also be disclosed.</li><br><li> <b>IRB Approval and Informed Consent Process</b>: If the study was reviewed by an Institutional Review Board (IRB) or an equivalent ethics committee, the paper should state this, including any IRB approval numbers or statements of exemption, while maintaining anonymity for blind review purposes. If specific IRB approval was not obtained, provide a justification based on the ethical guidelines followed (e.g., exemption due to minimal risk). Also, describe the informed consent process, ensuring that participants were aware of the research purpose, their rights, and could consent or withdraw without penalties.</li><br><li> <b>Clarification on Data Privacy and Anonymization</b>: Given the sensitive nature of historical documents and the involvement of human annotators, clarify how data privacy was ensured, especially in terms of anonymizing participants' data and protecting any potentially sensitive information contained in the dataset.</li><br><li> <b>Impact on Participants and Mitigation Strategies</b>: Discuss any potential negative impacts on the human annotators or individuals depicted or mentioned in the historical documents and outline measures taken to mitigate these risks.</li><br><li> <b>Ensuring the Paper Aligns with NeurIPS Ethical Guidelines</b>: Revisit the NeurIPS guidelines on ethics and ensure the paper's content complies with these, especially concerning transparency, accountability, and respect for all participants involved in the research.</li><br></ol>Inclusion of the above details will not only enhance the paper's compliance with ethical standards but also enrich the readers' understanding of the methodological rigor and ethical considerations underlying the creation and validation of the HHD-Ethiopic dataset.<br></div>
            <a class="move-to-top" href="#summary-question-15">↑ Back to summary</a>
        </div>
        

        <!-- Survey -->
        <div>
            <p>Please complete the following survey about your experience:</p>
            <a class="button" href="https://docs.google.com/forms/d/e/1FAIpQLScr4fjvUGhtiTzBfsqm5CCVvAGafp3sLSSB_Txz2YHhnLiiyw/viewform?usp=pp_url&entry.1830873891=SEhELUV0aGlvcGljIEEgSGlzdG9yaWNhbCBIYW5kd3JpdHRlbiBEYXRhc2V0IGZvciBFdGhpb3BpYyBPQ1Igd2l0aCBCYXNlbGluZSBNb2RlbHMgYW5kIEh1bWFuLWxldmVsIFBlcmZvcm1hbmNl" target="_blank">Click to submit post submission survey</a>
            <p>Your feedback is critical to evaluate the effectiveness of this LLM checklist assistant!</p>
        </div>
        
    </div>
</div>

</body>
</html>