Question,Question_Title,Answer,Justification,Guidelines,Review,Correctness_Score
Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope?,Claims,No,We haven't mentioned the main claims in the abstract and introduction,"• The answer NA means that the abstract and introduction do not include the claims made in the paper. • The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. • The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. • It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. . ","The justification provided in the review does not accurately reflect the content of the paper. The abstract and introduction sections of the paper do clearly outline the main claims and contributions of the work. Specifically, the abstract introduces Meta-Album as an extensible image classification meta-dataset designed to facilitate research in few-shot learning, meta-learning, and transfer learning. It mentions the inclusion of 40 datasets from diverse domains, the provision of three versions of each dataset to match computational resources, and the initiative to enlarge the meta-dataset through community contributions. Similarly, the introduction section elaborates on the motivation behind Meta-Album, contrasts it with existing benchmarks, and outlines its contributions in more detail. Therefore, the claim that the main claims are not mentioned in the abstract and introduction is inconsistent with the content of the paper.

Suggestions for improvement:
1. Ensure that the review comments are based on a thorough reading and accurate understanding of the paper content. Misinterpretations or overlooking key sections can lead to incorrect assessments.
2. Provide specific examples or quotes from the paper when claiming that certain information is missing or inadequately presented. This helps to substantiate the review's claims and provides actionable feedback to the authors.
3. Focus on constructive criticism that helps the authors improve their paper. If you believe that the abstract and introduction could more effectively communicate the paper's contributions, suggest how they could be revised to achieve this.
4. Re-evaluate the justification provided for answering this question, considering the detailed information presented in the abstract and introduction sections of the paper.",0
Does the paper discuss the limitations of the work performed by the authors?,Limitations,Yes,We have clearly explained the limitations of our work in Section: Discussion and conclusion,"• The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. • The authors are encouraged to create a separate """" section in their paper. • The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. • The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. • The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. • The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. • If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. • While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. . ","Justification:
Although the authors mention they have clearly explained the limitations of their work in the ""Discussion and conclusion"" section, the provided content overview does not specifically outline the detailed limitations. The guidelines provided for discussing the limitations of a work are extensive and cover various aspects such as assumptions, scope of claims, factors influencing performance, computational efficiency, and considerations of privacy and fairness. Without specific details from the ""Discussion and conclusion"" section about how these elements are addressed as limitations in the paper, it is challenging to verify the completeness of their discussion on limitations.

Constructive and actionable suggestions:
1. **Explicitly Address Assumptions and Robustness:** Clearly state any assumptions made during the research and discuss the robustness of your findings against potential violations of these assumptions. Consider including a subsection specifically dedicated to assumptions and their implications for the validity of your conclusions.

2. **Scope and Generalizability of Claims:** Reflect on the datasets, settings, or conditions under which your findings hold. If your experiments are limited to specific types of data or situations, acknowledge these as limitations and suggest avenues for future research to address these gaps.

3. **Performance Influencing Factors:** Identify and discuss any specific conditions or factors that significantly influence the performance of your proposed methods. This will help readers better understand under what circumstances your approach is most effective or may falter.

4. **Computational Efficiency:** Provide a detailed evaluation of the computational demands of your algorithms, including how they scale with increasing data size and complexity. This discussion is crucial for readers to assess the practical applicability of your methods.

5. **Privacy and Fairness:** If applicable, address any potential limitations of your approach in safeguarding privacy and ensuring fairness. Discuss measures that could be taken to mitigate these limitations.

6. **Encouragement of Transparency:** Reassure readers that acknowledging limitations is an integral part of scientific rigor and does not diminish the value of your contributions. Encourage an open dialogue about potential shortcomings and future research directions.

By addressing these points more explicitly in your ""Discussion and conclusion"" section, you can provide a more comprehensive understanding of the limitations of your work and pave the way for future improvements and research.",0
"For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof?",Theoritical assumptions and proofs,Yes,We have detailed all the theoretical proofs in the main paper.,"• The answer NA means that the paper does not include theoretical results. • All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced. • All assumptions should be clearly stated or referenced in the statement of any theorems. • The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. • Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. • Theorems and Lemmas that the proof relies upon should be properly referenced. . ","Justification: The answer provided by the authors is not consistent with the content of the paper as presented. The article introduces ""Meta-Album: Multi-domain Meta-Dataset for Few-Shot Image Classification,"" focusing on a practical resource for facilitating research on few-shot learning, not theoretical results or proofs. The paper primarily discusses dataset preparation, methodology for assembling and preprocessing the datasets, and utility demonstrations through various learning experiments. There is no discussion of theoretical results that would necessitate formal proofs or a detailed exposition of mathematical foundations. Thus, the statement about detailed theoretical proofs being included in the main paper does not apply.

Constructive and Actionable Suggestions:
1. Clarification: The authors should clarify the nature and scope of the paper to properly align with the questionnaire response. If the paper indeed has theoretical aspects mistakenly omitted from the provided content summary, these should be highlighted and detailed in the revision.

2. Detailed Description: If the article inadvertently omitted discussing theoretical results which include proofs or mathematical formulations, the authors are encouraged to provide a section dedicated to these aspects, along with clear statements of any assumptions made and precise references to any existing theorems or lemmas used.

3. Proof Sketches: For any theoretical assertions made, consider adding brief sketches of proofs in the main text to offer intuition, followed by detailed proofs in an appendix to maintain the readability and flow of the main paper.

4. Cross-referencing: Ensure that any theorems, lemmas, or important equations introduced are correctly numbered and cross-referenced within the text for ease of navigation and verification by the reader.

5. Correcting the Response: If the paper does not actually contain theoretical results as traditionally understood in mathematical or computational theory, the response to the checklist question should be corrected to accurately reflect the content, potentially as ""N/A"" if applicable.",0
Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)?,Experiments reproducibility,No,Our work is proprietary and we are not making the code and data available for public,"• The answer NA means that paper does not include experiments requiring code. • Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details. • While we encourage the release of code and data, we understand that this might not be possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark). • The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details. • The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc. • The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why. • At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). • Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. . ","The justification for not disclosing all the information needed to reproduce the main experimental results contradicts the provided guidelines and the ethos of scientific research, especially for a conference like NeurIPS. The proprietary nature of the work does not absolve the responsibility to enable reproducibility of results to the extent possible without divulging sensitive or proprietary information. While it is understood that not all papers can release code and data due to various constraints, the expectation is to provide a detailed methodology, algorithms used, and pseudocode or descriptions that allow for the reproduction of the results.

**Constructive Suggestions:**
1. **Methodology Description:** Enhance the paper by describing the methodology in greater detail. Include precise descriptions of the algorithms, model architectures, hyperparameters, and training procedures used.
   
2. **Pseudocode:** Include pseudocode for the principal algorithms developed or used in the study. This helps in understanding the algorithmic contributions without needing to access the proprietary code.
   
3. **Synthetic or Sample Data:** If possible, provide synthetic or anonymized sample data that can help understand the data structures and formats expected by the algorithms. This would also assist in independent implementations.
   
4. **Detailed Experimental Setup:** Elaborate on the experimental setup, including hardware specifications, software environments, and libraries used. Providing version numbers for software dependencies can significantly improve reproducibility.
   
5. **Statistical Analysis and Metrics:** Clarify the statistical methods and metrics used to evaluate the models. If certain parts of the analysis are omitted from reproducibility efforts, explain why and describe how to perform these analyses.
   
6. **Expanded Supplemental Material:** Consider expanding the supplemental material to include any additional information that could aid in reproducibility. This might include configuration files, environment setup instructions, or detailed datasets statistics.
   
7. **FAQs or Troubleshooting Guide:** Anticipate common challenges that researchers might face when trying to reproduce the results and provide an FAQ or troubleshooting guide based on the experiences of conducting the experiments.

By addressing these points, the authors can significantly improve the reproducibility of their work, even in situations where direct access to code and proprietary data sets cannot be provided.",0
"Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material?",Code and data accessibility,No,Our work is proprietary and we are not making the code and data available for public,"• The answer NA means that paper does not include experiments requiring code. • Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details. • While we encourage the release of code and data, we understand that this might not be possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark). • The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details. • The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc. • The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why. • At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). • Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. . ","The justification provided by the authors conflicts with the content presented in the paper. The paper clearly mentions the availability of source code, baseline methods, data loaders, and instructions for contributing either new datasets or algorithms to the expandable meta-dataset on their website (https://meta-album.github.io/). Additionally, it mentions the intention to open-source the code used for several use cases, including transfer learning, few-shot meta-learning, and cross-domain few-shot meta-learning tasks. Therefore, the statement in the justification claiming that the work is proprietary and the code and data are not available for the public is inconsistent with the details provided in the paper.

Constructive and actionable suggestions for the authors would include:

1. Clarifying the discrepancy between the justification given for this question and the details provided in the paper regarding the availability of code and data. If the code and datasets are indeed available, consider emphasizing their accessibility more clearly in the response to this question.

2. Ensuring that the repository linked in the paper includes comprehensive documentation, including step-by-step instructions to replicate the main experimental results. This documentation should cover environment setup, dataset preparation, model training, and evaluation.

3. If applicable, specifying any parts of the experiments or analyses that cannot be directly reproduced using the provided resources, along with explanations for these limitations.

4. Updating the supplemental material or the paper itself to include any additional details about code and data release that can help with reproducibility but might not fit into the main text of the paper due to space limitations.

5. Considering the use of Docker containers or similar tools to package the experimental environment, which can significantly simplify the process of replicating the results.",0
"Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results?",Experimental settings/details,Yes,We have explained the experimental settings or details in Section 3.2: Experiments.,"• The answer NA means that the paper does not include experiments. • The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. • The full details can be provided either with the code, in appendix, or as supplemental material. . ","Justification for the score:
While the authors mention that experimental settings or details are provided in Section 3.2, the provided excerpt offers limited insight into the specifics of the training and testing methodology, which are crucial for reproducing the results and fully understanding the conclusions of the paper. Specifically, the excerpt does not clearly specify the following:

1. **Data Splits**: Details about how the data is divided into training, validation, and test sets are not thoroughly described. Understanding how datasets are partitioned is essential for appreciating the generalization capability of the proposed methods.

2. **Hyperparameters**: There is no explicit mention of how hyperparameters were chosen or optimized. Details such as the learning rate, batch size, or any regularization techniques used are critical for replicating the study.

3. **Optimizer**: The type of optimizer used in the experiments is not specified. The choice of optimizer can significantly affect the performance of deep learning models, hence its specification is necessary.

4. **Reproducibility**: For readers to fully appreciate and verify the results presented in the paper, it's crucial to provide details that allow for the exact replication of the experiments, including any random seeds used.

Constructive suggestions for improvement:

1. **Data Splits**: Provide detailed explanations of how the datasets are divided into training, validation, and test sets. Mention any stratification or specific considerations taken into account while splitting the datasets.

2. **Hyperparameters**: Clearly specify all hyperparameters used in the experiments. If hyperparameter tuning was conducted, describe the method or rationale behind the chosen values.

3. **Optimizer Details**: Include information about the optimizer utilized in the experiments (e.g., SGD, Adam). If relevant, also mention the learning rate, momentum, or other optimizer-specific hyperparameters.

4. **Reproducibility**: Ensure that all information necessary to replicate the experiments is included. This could involve specifying random seeds, providing exact versions of software and libraries used, and giving access to pre-processed data when applicable.

5. **Supplementary Materials**: Consider providing extensive experimental details, including hyperparameters and data processing steps, in appendices or supplementary materials if space constraints are a concern in the main text.

These suggestions aim to enhance the clarity, completeness, and reproducibility of the experimental methodology, thereby assisting readers in fully comprehending and verifying the research findings.",0
Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments?,Error bars,Yes,We have reported error bars in Section 3.2: Experiments.,"• The answer NA means that the paper does not include experiments. • The authors should answer ""Yes"" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. • The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions). • The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.) • The assumptions made should be given (e.g., Normally distributed errors). • It should be clear whether the error bar is the standard deviation or the standard error of the mean. • It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified. • For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates). • If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. . ","Justification Review:
The answer provided by the authors indicates a positive response to the choice of reporting error bars. However, the justification simply states where error bars are reported without explicitly addressing the guidelines regarding the clarity and correctness of how these are defined or any relevant details that demonstrate their statistical significance. Specifically, the justification lacks:

1. Explanation of what the error bars represent (e.g., standard deviation, standard error of the mean, confidence intervals, etc.).
2. The method used for calculating the error bars (e.g., closed-form formula, library function, bootstrap, etc.).
3. Discussion on the assumptions made (e.g., normally distributed errors) and their verification.
4. Specification of whether the error bars are symmetric or asymmetric and how out-of-range values are handled.
5. Explicit referencing of the figures or tables in the text where these error bars are discussed, along with an explanation of their relevance to the main claims of the paper.

This lack of detail in the justification makes it difficult to assess the appropriateness and correctness of the error bars reported, which is crucial for understanding the statistical significance of the experiments.

Actionable Suggestions:
1. Provide detailed explanations about the type of error bars used and their statistical significance in relation to the main claims of the paper.
2. Clearly outline the methods used for calculating error bars and the assumptions made in this process.
3. Discuss how error bars are interpreted in the context of the study, especially if asymmetric ranges are utilized.
4. Ensure that any mention of error bars in figures or tables is accompanied by thorough explanations in the text, linking these statistical representations back to the paper's primary findings.
5. Consider including a subsection or paragraph in the methodology section that addresses these points comprehensively, enhancing the paper's transparency and replicability.",0
"For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments?",Compute resources,Yes,"We have provided details about compute resources used in Section 3.2: Experiments, Appendix E: Within Domain Few-shot learning, and Appendix F: Cross-Domain Few-shot learning","• The answer NA means that the paper does not include experiments. • The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. • The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. • The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper). . ","The justification provided by the authors claiming that details about compute resources used in the experiments are provided in Section 3.2 and Appendices E and F does not fully comply with the guidelines provided for disclosing computational resources. While the authors mention the sections where compute resources information can supposedly be found, a review of those sections in the provided content shows that specific details, such as the type of compute workers (CPU/GPU), specifics about the internal cluster or cloud provider, memory, storage, and execution time estimates for individual runs and the total compute estimation, are missing or not explicitly stated. This lack of detailed information affects the reproducibility of the experiments, as other researchers cannot gauge the computational cost or infrastructure requirements to replicate the study.

Constructive and actionable suggestions:
1. Specify the type of compute resources used for the experiments (e.g., GPU model, CPU specifications).
2. Include details about the computational infrastructure, such as whether experiments were run on an internal cluster, specific cloud provider instances, and any relevant configurations.
3. Disclose the memory and storage requirements for running the experiments to help others plan the replication study appropriately.
4. Provide detailed execution time for each experiment, including preprocessing, training, and evaluation phases, to offer a clear view of the time investment required.
5. If applicable, mention any additional computational resources that were utilized for preliminary studies or experiments not included in the final paper to give a complete picture of the computational effort involved in the research project.",0
"Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?",NeruIPS code of ethics,No,We are not bound to follow the NeurIPS code of ethics,"• The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. • If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. • The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). . ","Justification for the Score:
The answer provided by the authors is inconsistent with the expectations set by the NeurIPS conference regarding adherence to ethical guidelines. The NeurIPS Code of Ethics is designed to ensure the research presented at the conference is ethically sound and conducted responsibly. The assertion that the authors are ""not bound to follow the NeurIPS code of ethics"" directly contradicts the conference's requirements and raises serious concerns about the ethical considerations behind the research. All submissions to NeurIPS must conform to its Code of Ethics, and any deviations must be carefully and clearly justified, taking into account legal, geographical, or other exceptional circumstances. Simply stating non-adherence without substantial justification does not meet the ethical standards expected.

Constructive and Actionable Suggestions:
1. **Review the NeurIPS Code of Ethics**: Authors should thoroughly review the NeurIPS Code of Ethics and evaluate their research against all the points mentioned in the guidelines. This will ensure that their research aligns with the ethical standards set by the conference.

2. **Provide a Detailed Explanation**: If there are any areas where the research deviates from these guidelines, the authors must provide detailed explanations for each deviation. This should include the reasons behind the deviation and any measures taken to mitigate potential ethical concerns.

3. **Mitigation Strategies**: For any identified ethical issues or deviations from the Code of Ethics, authors should discuss how they addressed or plan to address these issues. This could include modifications to the study design, additional oversight, or other ethical safeguards.

4. **Consult Ethics Boards**: If applicable, consulting with Institutional Review Boards (IRBs) or ethics committees and including their input or approval in the paper can provide additional assurance that the research adheres to ethical standards.

5. **Revise the Statement**: Authors should revise their ethical statement to affirm that the research either adheres to the NeurIPS Code of Ethics or provide a clearly justified and detailed explanation of any exceptions due to special circumstances.

By addressing these suggestions, the authors can ensure that their paper meets the ethical standards expected by the NeurIPS conference and the broader research community.",0
Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed?,Impacts,Yes,We have detailed potential impacts and recommended use in Section 1.3,"• The answer NA means that there is no societal impact of the work performed. • If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. • Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations. • The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. • The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. • If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). . ","Justification for the Score:
The provided answer by the authors states that ""We have detailed potential impacts and recommended use in Section 1.3,"" which suggests a discussion on societal impacts. However, the justification is overly generic and lacks specificity regarding how the paper discusses both potential positive and negative societal impacts.

Constructive and Actionable Suggestions:
- The authors should explicitly list and elaborate on the specific positive societal impacts their work could have. For instance, how could the Meta-Album meta-dataset facilitate research in cross-domain meta-learning and contribute to advancements in few-shot learning methodologies that could benefit various fields such as healthcare, ecology, or automated systems?
- The paper should also consider and explicitly discuss potential negative societal impacts. For example, could the advanced image classification techniques enabled by the dataset be misused for surveillance or in ways that could infringe on privacy? Are there fairness and bias considerations, especially given the dataset's multi-domain nature, that need to be addressed to ensure equitable model performance across different contexts?
- To strengthen the discussion on societal impacts, the authors could propose concrete mitigation strategies for any identified negative impacts. This might include recommendations for ethical use guidelines, considerations for the responsible deployment of technologies developed using their dataset, and suggestions for future work to address any biases or fairness issues.
- If Section 1.3 does indeed address these aspects in detail, the authors should provide a more thorough explanation in their justification, with direct references to specific discussions or findings within that section that highlight the consideration of both positive and negative societal impacts of their work.",0
"Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)?",Safeguards,Yes,"Indeed, we are releasing our datasets with proper license and terms of use. We have also provided recommended usage of these datasets.","• The answer NA means that the paper poses no such risks. • Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. • Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. • We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. . ","The provided justification in the paper's response does not thoroughly address the potential risks associated with the datasets and models, especially when considering responsible release and the prevention of misuse. While mentioning that datasets will be released with appropriate licenses and recommended uses, the answer lacks details about specific measures or safeguards that have been proactively put in place to ensure responsible use. Considering the wide range of domains covered by the Meta-Album project and the potential for misuse, a more detailed explanation of these safeguards is necessary. 

Constructive and actionable suggestions for improvement:
1. **Detailed Safeguards Description**: Clearly articulate the specific safeguards or protocols you have established to mitigate risks associated with the data or models. This includes both technical measures (e.g., access controls, user agreements) and ethical considerations (e.g., ensuring diversity in dataset representation, privacy protections for individuals in the dataset).

2. **License Explanation**: Elaborate on the types of licenses under which the datasets are released. Discuss how these licenses specifically aim to prevent misuse or unethical use of the data. Providing examples of allowed and disallowed uses under these licenses could be beneficial.

3. **Data Collection and Curation Process**: Address any ethical considerations in the data collection and curation process, especially for datasets that are sensitive or have potential for misuse. Explain how consent was obtained, how privacy was ensured, and any steps taken to anonymize or protect sensitive information.

4. **Misuse Prevention Strategies**: Discuss strategies or mechanisms you've considered to monitor and prevent misuse of the datasets and models once they are released. This could include a reporting mechanism for misuse, regular reviews of how the data is being used, or collaborations with ethics boards.

5. **Community Engagement**: Consider engaging with the broader research or user community to continually assess and address ethical concerns related to the datasets and models. Establishing an open dialogue can help identify unforeseen risks and develop community standards for responsible use.

Providing more comprehensive details on these points within the paper will strengthen the justification for the responsible release claim and ensure that potential risks are adequately mitigated.",0
"Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected?",Credits,Yes,"We are releasing our datasets with proper license, we are also mentioning the original licenses for the original datasets in Appendix B: License information of Meta-Album datasets","• The answer NA means that the paper does not use existing assets. • The authors should cite the original paper that produced the code package or dataset. • The authors should state which version of the asset is used and, if possible, include a URL. • The name of the license (e.g., CC-BY 4.0) should be included for each asset. • For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided. • If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset. • For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. • If this information is not available online, the authors are encouraged to reach out to the asset's creators. . ","The authors have clearly stated their compliance with licensing and terms of use for the datasets utilized in their paper. Specifically, they mention that they are releasing their datasets with proper licensing and are also acknowledging the original licenses for the datasets they sourced in Appendix B: License information of Meta-Album datasets. This demonstrates respect for intellectual property and adherence to the ethical norms of scientific research.

However, as constructive criticism to further improve the clarity and compliance on licensing issues, the authors may consider the following suggestions:
1. **Explicitly State Licenses in the Main Text:** While mentioned in the appendix, it might add clarity to briefly mention in the main body of the paper the type of licenses under which the Meta-Album datasets are released and a general statement about the licensing of the original datasets.
2. **Provide Direct Links to Licenses:** Where possible, include direct links or references to the specific licenses of the original datasets within Appendix B. This can help readers and future researchers easily access and understand the terms under which the data can be used.
3. **Clarification on Derivative Works:** If any preprocessing or modifications were made to the original datasets, it would be beneficial to clarify the licensing implications for these derivative works. For example, whether the preprocessing aligns with the terms of the original licenses and if there are any changes in the licensing terms for the processed datasets.
4. **Guidance for Reusers:** Offer some guidance or recommendations for researchers who might want to use the Meta-Album datasets or its derivatives, citing specific do's and don’ts based on the licensing terms.

These additional steps can ensure complete transparency and foster trust in the scientific community, encouraging the respectful and lawful use of shared resources.",1
Are new assets introduced in the paper well documented and is the documentation provided alongside the assets?,Documentation,Yes,We have properly documented our new datasets using meta-data files and datasheets for datasets (provided in the appendices).,"• The answer NA means that the paper does not release new assets. • Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc. • The paper should discuss whether and how consent was obtained from people whose asset is used. • At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. . ","The provided justification does not fully align with the suggested guidelines for documenting new assets introduced in a paper. While the response mentions the use of meta-data files and datasheets for datasets provided in the appendices, it does not specifically address several key aspects outlined in the guidelines:

1. The response lacks detailed information on the structured templates used for documenting the datasets/code/model. It's essential to outline how the datasets are structured, along with details about training, license, limitations, and other relevant aspects.
2. There is no discussion on how consent was obtained from people whose assets are used, which is a crucial part of ensuring ethical research practices.
3. The response does not address the anonymization of assets, which is vital for maintaining confidentiality and adhering to the submission guidelines.

**Constructive and Actionable Suggestions:**

1. **Structured Documentation:** The authors should provide a clearer and more detailed description of the structured templates used for documenting the new assets. This documentation should include specifics on training parameters, data collection methodologies, licensing information, and any limitations or biases in the datasets.

2. **Consent and Ethics:** The paper should explicitly discuss how consent was obtained from individuals or entities whose assets are used in the research. This includes any personal data, proprietary information, or copyrighted materials within the datasets.

3. **Anonymization:** If applicable, the authors should clarify the steps taken to anonymize the assets, ensuring the privacy and confidentiality of any individuals or entities involved. The paper should provide details on how anonymized URLs or files were created and handled during the submission process.

4. **Accessibility and License:** The documentation should include information on how interested researchers can access the datasets or code, and under what license they are made available. This promotes transparency and reproducibility in research.

By addressing these suggestions, the authors can significantly improve the documentation of the new assets introduced in the paper, ensuring compliance with ethical guidelines and enhancing the utility and accessibility of their research contributions.",0
"For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)?",Human subjects,Yes,We have mentioned all the crowdsourcing details in the main paper,"• The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. • Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper. • According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. . ","Justification for the Score:
Based on the content provided in the paper review, it appears that the authors have not included the detailed information required in response to the question about crowdsourcing experiments and research with human subjects. Merely stating that ""all the crowdsourcing details are mentioned in the main paper"" does not provide evidence of the inclusion of full instructions given to participants, screenshots (if applicable), or details about compensation, which are critical aspects of this question as per the guidelines.

Constructive and Actionable Suggestions for Improvement:

1. **Detailed Instructions:** Please include the full text of the instructions given to the participants in your crowdsourcing experiments in the supplemental material or ideally, in an appendix within the main paper if space allows. This will provide readers with a clearer understanding of the experimental setup and procedures followed.

2. **Screenshots:** If applicable, consider adding screenshots of the crowdsourcing interface or the tasks that participants were asked to complete. This can be included in the supplemental materials and referenced in the main paper. Screenshots will help readers visualize the tasks and potentially reproduce your study.

3. **Compensation Details:** It's crucial to disclose details about compensation for the participants involved in your study. This transparency is important for ethical considerations and aligns with the NeurIPS Code of Ethics. Please specify the compensation rates, how they compare to minimum wage standards in the participants' countries, and any other benefits provided to the participants.

4. **Ethical Considerations:** Alongside the aforementioned details, also highlight any ethical considerations or approvals obtained (if applicable) from an institutional review board (IRB) or equivalent ethics committee. This will demonstrate compliance with ethical standards in research involving human subjects.

By addressing these aspects, the paper will meet the NeurIPS guidelines more thoroughly and provide a transparent and ethical account of the research involving human participants.",0
"Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained?",Risks,Yes,We have received approvals from IRB and have mentioned in the main paper,"• The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. • Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper. • We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution. • For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.","Justification provided by the authors regarding IRB approvals does not align with the content of the paper provided for review. The paper introduces Meta-Album, an extensive image classification meta-dataset designed to facilitate few-shot learning, transfer learning, meta-learning, among other tasks. However, there is no specific section or mention regarding the involvement of human subjects directly in research that would necessitate IRB approvals or discussions of potential risks incurred by study participants. The paper mainly focuses on the creation, structure, and utility of the Meta-Album dataset, benchmark comparisons, and the technical aspects of handling and contributing to the dataset. Since the primary focus is on the dataset itself and computational tasks related to it, it appears that the nature of the research does not directly involve human subjects in a way that would typically require IRB review.

**Constructive Suggestions:**
1. **Clarify Involvement of Human Subjects:** If the project involves human subjects in any way not apparent from the review materials, such as in dataset collection or experiments involving human evaluation, please clarify these aspects and their ethical considerations more explicitly in the paper.

2. **Details on Ethical Considerations:** If there were indeed aspects of the research that required IRB approval, such as user studies, data collection from human subjects, or other forms of direct human involvement, provide a dedicated section or paragraph detailing the ethical considerations, the nature of the involvement, how consent was obtained, and any measures taken to ensure the confidentiality and well-being of participants.

3. **Specify Institutional Review (If Applicable):** If your institution reviewed the project and determined it did not require formal IRB approval, mentioning this decision can help clarify the ethical landscape of your research. This could include a statement on why IRB approval was not necessary.

4. **Adhere to Anonymity Guidelines:** If this information is to be included in an initial submission that requires anonymization, ensure that mentioning the review process does not compromise the double-blind review process. A generic statement indicating ethical considerations were reviewed and approved by the appropriate institutional review board or ethics committee suffices for the initial anonymous submission.

5. **Improve Transparency:** For projects that heavily depend on datasets involving humans (even indirectly, through the images used), enhancing transparency about data sourcing, curation, and usage rights can contribute positively toward the ethical considerations of your paper.",0
