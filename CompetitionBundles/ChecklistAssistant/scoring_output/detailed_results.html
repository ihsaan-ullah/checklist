<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<style>
    body {
        font-family: Arial, sans-serif;
        margin: 0;
        padding: 0;
        box-sizing: border-box;
    }
    .container {
        margin: 20px auto;
        padding: 0 20px;
        position: relative;
    }
    .button {
        padding: 10px;
        font-size: 16px;
        text-align: center;
        background-color: #f93361;
        color: #fff;
        border: none;
        border-radius: 5px;
        cursor: pointer;
        text-decoration: none;
        position: absolute;
    }
    .button-top {
        top: 10px;
        right: 20px;
    }
    .button-bottom {
        bottom: 10px;
        right: 20px;
    }
    .button:hover {
        background-color: #bc0530;
    }
    .content {
        padding-top: 60px; /* Adjust according to button height and margin */
        padding-bottom: 40px; /* Add padding instead of margin */
        margin-bottom: 20px;
    }
    h1 {
        margin-top: 0; /* Remove default margin */
        margin-bottom: 30px;
    }
    hr {
        margin-top: 50px;
        margin-bottom: 50px;
    }
    .review {
        margin-bottom: 30px;
        border: 1px solid #ccc;
        padding: 20px;
        border-radius: 5px;
        background-color: #f9f9f9;
    }
    .review h2 {
        margin-top: 0;
    }
    .review p {
        margin: 10px 0;
    }
    .question {
        color: #0033ff;
    }
    .answer {
        color: #28a745;
    }
    .justification {
        color: #de750b;
    }
    .llm_review {
        color: #000;
        background-color: #c3defb;
        border: 1px solid #007bff;
        padding: 20px;
        border-radius: 5px;
    }

    table {
        border-collapse: collapse;
    }
    th, td {
        padding: 8px;
        text-align: left;
        border-bottom: 1px solid #ddd;
    }
    th {
        background-color: #f2f2f2;
    }
    .score-label {
        display: inline-block;
        padding: 5px 15px;
        border-radius: 5px;
        text-decoration: none;
    }
    .score-green {
        background-color: #c8e6c9;
        color: #1b5e20;
        border: 1px solid #1b5e20;
    }
    .score-red {
        background-color: #e6c8c8;
        color: #5e1b1b;
        border: 1px solid #5e1b1b;
    }
    .score-blue {
        background-color: #c8d8e6;
        color: #1b455e;
        border: 1px solid #1b455e;
    }
    .scroll-button {
        padding: 10px 20px;
        font-size: 14px;
        color: #212121;
        border: 1px solid #212121;
        border-radius: 5px;
        cursor: pointer;
        text-decoration: none;
    }
    .scroll-button:hover {
        background-color: #212121;
        color: #fff;
    }
    .move-to-top {
        padding: 5px 10px;
        font-size: 12px;
        color: #212121;
        border: 1px solid #212121;
        border-radius: 3px;
        cursor: pointer;
        text-decoration: none;
    }
    .move-to-top:hover {
        background-color: #212121;
        color: #fff;
    }
</style>
</head>
<body>

<div class="container">

    <a class="button button-top" href="https://docs.google.com/forms/d/e/1FAIpQLSfRIDkcXFbsOrR09j4qA1MlG4Rfir2lPD_u9YC4eqKBJ8tHkw/viewform?usp=pp_url&entry.1830873891=TWV0YS1BbGJ1bTogTXVsdGktZG9tYWluIE1ldGEtRGF0YXNldCBmb3JGZXctU2hvdCBJbWFnZSBDbGFzc2lmaWNhdGlvbg==" target="_blank">Click to submit post submission survey</a>

    <div class="content">
        <h1>Meta-Album: Multi-domain Meta-Dataset forFew-Shot Image Classification</h1>

        <hr>

        <h2>Scores</h2>
        <table>
            <tr>
              <td><strong>Correctness Score:</strong></td>
              <td><span class="score-label score-blue">0.67</span></td>
            </tr>
            
            
        </table>

        <hr>

        <h2>Review Summary</h2>
        <table>
            <tr>
              <th>Question</th>
              <th>Score</th>
              <th>Details</th>
            </tr>
            
                
                
                <tr id="summary-Genuine-question-1">
                    <td>1. Claims</td>
                    <td><span class="score-label score-green">1</span></td>
                    <td><a href="#Genuine-question-1" class="scroll-button">Detailed Review</a></td>
                  </tr>
                
                <tr id="summary-Genuine-question-2">
                    <td>2. Limitations</td>
                    <td><span class="score-label score-green">1</span></td>
                    <td><a href="#Genuine-question-2" class="scroll-button">Detailed Review</a></td>
                  </tr>
                
                <tr id="summary-Genuine-question-3">
                    <td>3. Theoritical assumptions and proofs</td>
                    <td><span class="score-label score-green">1</span></td>
                    <td><a href="#Genuine-question-3" class="scroll-button">Detailed Review</a></td>
                  </tr>
                
                <tr id="summary-Genuine-question-4">
                    <td>4. Experiments reproducibility</td>
                    <td><span class="score-label score-red">0</span></td>
                    <td><a href="#Genuine-question-4" class="scroll-button">Detailed Review</a></td>
                  </tr>
                
                <tr id="summary-Genuine-question-5">
                    <td>5. Code and data accessibility</td>
                    <td><span class="score-label score-green">1</span></td>
                    <td><a href="#Genuine-question-5" class="scroll-button">Detailed Review</a></td>
                  </tr>
                
                <tr id="summary-Genuine-question-6">
                    <td>6. Experimental settings/details</td>
                    <td><span class="score-label score-red">0</span></td>
                    <td><a href="#Genuine-question-6" class="scroll-button">Detailed Review</a></td>
                  </tr>
                
                <tr id="summary-Genuine-question-7">
                    <td>7. Error bars</td>
                    <td><span class="score-label score-green">1</span></td>
                    <td><a href="#Genuine-question-7" class="scroll-button">Detailed Review</a></td>
                  </tr>
                
                <tr id="summary-Genuine-question-8">
                    <td>8. Compute resources</td>
                    <td><span class="score-label score-red">0</span></td>
                    <td><a href="#Genuine-question-8" class="scroll-button">Detailed Review</a></td>
                  </tr>
                
                <tr id="summary-Genuine-question-9">
                    <td>9. NeruIPS code of ethics</td>
                    <td><span class="score-label score-green">1</span></td>
                    <td><a href="#Genuine-question-9" class="scroll-button">Detailed Review</a></td>
                  </tr>
                
                <tr id="summary-Genuine-question-10">
                    <td>10. Impacts</td>
                    <td><span class="score-label score-green">1</span></td>
                    <td><a href="#Genuine-question-10" class="scroll-button">Detailed Review</a></td>
                  </tr>
                
                <tr id="summary-Genuine-question-11">
                    <td>11. Safeguards</td>
                    <td><span class="score-label score-red">0</span></td>
                    <td><a href="#Genuine-question-11" class="scroll-button">Detailed Review</a></td>
                  </tr>
                
                <tr id="summary-Genuine-question-12">
                    <td>12. Credits</td>
                    <td><span class="score-label score-green">1</span></td>
                    <td><a href="#Genuine-question-12" class="scroll-button">Detailed Review</a></td>
                  </tr>
                
                <tr id="summary-Genuine-question-13">
                    <td>13. Documentation</td>
                    <td><span class="score-label score-green">1</span></td>
                    <td><a href="#Genuine-question-13" class="scroll-button">Detailed Review</a></td>
                  </tr>
                
                <tr id="summary-Genuine-question-14">
                    <td>14. Human subjects</td>
                    <td><span class="score-label score-green">1</span></td>
                    <td><a href="#Genuine-question-14" class="scroll-button">Detailed Review</a></td>
                  </tr>
                
                <tr id="summary-Genuine-question-15">
                    <td>15. Risks</td>
                    <td><span class="score-label score-red">0</span></td>
                    <td><a href="#Genuine-question-15" class="scroll-button">Detailed Review</a></td>
                  </tr>
                
            
        </table>

        <hr>

        <h2>Detailed Review</h2>

        
            
            <p><strong>Correctness Score:</strong> 0.67</p>
        
            
            <div class="review" id="Genuine-question-1">
                <p><strong class="question">Question # 1:</strong> Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope?</p>
                <p><strong class="answer">Answer:</strong> Yes</p>
                <p><strong class="justification">Justification:</strong> The abstract and introduction clearly state the main contributions and scope of the paper</p>
                <p class="llm_review"><strong>Review:</strong> The response provided by the authors accurately reflects the content and contributions of the paper as presented in the abstract and introduction. The paper introduces Meta-Album, a multi-domain meta-dataset aimed at facilitating research in few-shot learning, meta-learning, and related tasks. The claims made in the abstract and introduction accurately outline the contributions, including the creation of the Meta-Album with 40 image classification datasets from various domains, the availability of the dataset in three versions to accommodate computational resources, and the provision of baseline methods and open-source code for community use. Furthermore, the paper discusses the importance of this work for cross-domain and domain-independent studies, adding to its contributions.<br><br>However, to ensure absolute clarity and consistency throughout, the authors could consider the following suggestions for improvement:<br><br>1. Emphasize the novelty: While the paper states its contributions, highlighting what makes Meta-Album uniquely beneficial compared to existing datasets and benchmarks could further strengthen the paper's impact. Specifically, elaborating on how Meta-Album addresses the limitations of current datasets in the field could provide clearer motivation for the study.<br><br>2. Clarify limitations: While the abstract and introduction set ambitious goals and contributions, briefly acknowledging any limitations or challenges encountered during the development and deployment of Meta-Album within these sections can enhance transparency and set realistic expectations for the readers.<br><br>3. Further detail on use cases: The introduction mentions facilitating research in few-shot learning, transfer learning, and meta-learning among other tasks. Expanding slightly on how Meta-Album specifically enables advancements in these areas or providing brief examples could help illustrate the practical implications and applications of the dataset more concretely.<br><br>By addressing these points, the authors can ensure that the claims made in the abstract and introduction not only accurately reflect the paper’s contributions but also clearly convey the significance and potential impact of their work to the readers.<br></p>
                <p><strong>Score:</strong> 1</p>
                <a class="move-to-top" href="#summary-Genuine-question-1">Jump to Summary</a>
            </div>
            
            <div class="review" id="Genuine-question-2">
                <p><strong class="question">Question # 2:</strong> Does the paper discuss the limitations of the work performed by the authors?</p>
                <p><strong class="answer">Answer:</strong> Yes</p>
                <p><strong class="justification">Justification:</strong> We have clearly explained the limitations of our work in Section: Discussion and conclusion</p>
                <p class="llm_review"><strong>Review:</strong> The authors claim they have discussed the limitations in the "Discussion and conclusion" section of their paper, as per the reviewer's question and the justification provided. A critical review of the provided abstract and sections related to discussions and conclusions indeed shows that the authors have tackled the limitation aspect of their work. They have reflected on the dataset's extensibility, potential biases, and the need for more challenging tasks, indicating a thoughtful consideration of the limitations and scope of their study.<br><br>However, to further enhance the paper's clarity and adherence to best practices concerning discussing limitations, the authors could consider the following suggestions:<br>1. Explicit Limitations Section: While discussing limitations within the "Discussion and conclusion" section is acceptable, having a dedicated "Limitations" section could make these discussions more visible and structured. This could help readers quickly understand the potential challenges and scope of applicability of the proposed methods and datasets.<br>2. Detailing Computational Efficiency: The authors might want to include more information on the computational efficiency of handling the Meta-Album and the scalability of the proposed methods. This is especially relevant since the dataset versions vary significantly in size, and computational resources vary among researchers.<br>3. Robustness and Assumptions: Elaborate further on the assumptions underlying the proposed methods or dataset curation. This includes assumptions about data quality, the representativeness of the classes, and the impact of these assumptions on the generalizability of the findings.<br>4. Performance Factors: While the paper discusses dataset features and preliminary results, further details on factors influencing performance across different domains could be insightful. This can include discussions on why certain domains might pose more challenges and how future methods could address these challenges.<br>5. Addressing Bias and Fairness: The authors hint at potential biases in the dataset preparation process. Expanding on how such biases could affect the learning outcomes and potential mitigation strategies would be informative. This also ties into broader discussions on fairness and ethical considerations in machine learning datasets.<br>6. Privacy Considerations: If applicable, discussions on privacy concerns, especially in datasets involving human subjects (directly or indirectly), could be a valuable addition.<br><br>By addressing these suggestions, the authors can provide a more comprehensive overview of their work's limitations, thus contributing to transparency, reproducibility, and the integrity of scientific research in machine learning.<br></p>
                <p><strong>Score:</strong> 1</p>
                <a class="move-to-top" href="#summary-Genuine-question-2">Jump to Summary</a>
            </div>
            
            <div class="review" id="Genuine-question-3">
                <p><strong class="question">Question # 3:</strong> For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof?</p>
                <p><strong class="answer">Answer:</strong> nan</p>
                <p><strong class="justification">Justification:</strong> This does not apply to our research work because our research is not theoretical rather it deals with a meta-dataset creation and experiments executed using this meta-dataset</p>
                <p class="llm_review"><strong>Review:</strong> The authors correctly labeled this section as N/A (Not Applicable) due to the nature of their work. Their research focuses on the creation of a new meta-dataset, "Meta-Album," and conducting experiments using this dataset. The submission is fundamentally empirical and does not delve into theoretical analysis that would necessitate the presentation of theorems, formulas, or proofs. This aligns well with the nature of the submission as a contribution to the field of few-shot learning and meta-learning through dataset development rather than theoretical model derivation or proof.<br><br>Given the empirical focus of the paper, the necessity for theoretical proofs or the full set of assumptions for theoretical results is indeed not applicable. The detailed description of the dataset, its preparation, presentation, and the experiments conducted provides the necessary information for the contribution to be evaluated on its empirical merits.<br><br>Actionable Suggestions for Further Clarity (even when N/A is a valid response):<br>1. While the section is correctly marked as N/A, the authors might consider adding a sentence to briefly clarify the empirical nature of their work early in the paper. This would set the correct expectations for readers and reviewers regarding the content and contributions of the paper.<br>2. It could be beneficial for the authors to discuss any assumptions made during the dataset creation process or during the experimental setup. While theoretical proofs are not applicable, understanding the assumptions behind the data collection, preprocessing, and choice of baseline methods could enhance the paper’s clarity and help assess the generalizability and applicability of the dataset.<br>3. Given the empirical nature of the work, authors are encouraged to thoroughly detail their experimental design, including any datasets comparisons, model training details, and evaluation metrics in the supplement material. This ensures the reproducibility and transparency of the experimental results reported.<br></p>
                <p><strong>Score:</strong> 1</p>
                <a class="move-to-top" href="#summary-Genuine-question-3">Jump to Summary</a>
            </div>
            
            <div class="review" id="Genuine-question-4">
                <p><strong class="question">Question # 4:</strong> Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)?</p>
                <p><strong class="answer">Answer:</strong> Yes</p>
                <p><strong class="justification">Justification:</strong> We have publicly provided the code on our github repository and details about how to access the datasets on our website.</p>
                <p class="llm_review"><strong>Review:</strong> Justification for the Score:<br>While the authors state that the code is publicly available on their GitHub repository and details about accessing the datasets are on their website, the provided answer lacks specificity regarding the comprehensiveness of this documentation. For reproducing the main experimental results, it's not just the availability of code and datasets that matters; detailed instructions, environment setups, and how to access and prepare the data are equally critical. The answer does not address whether explicit instructions, environmental requirements, or scripts to reproduce experiments are provided. Thus, the answer appears to lack critical details necessary to ensure the reproducibility of the experimental results.<br><br>Constructive and Actionable Suggestions:<br>1. Detailed Instructions: Provide a clear and detailed step-by-step guide in the paper or supplementary material on how to reproduce the experiments. This should include the exact commands and environment setup.<br><br>2. Environment Details: Specify the software versions, libraries, and any specific hardware requirements needed to replicate the research. If possible, include a Dockerfile or an environment.yml file that can automatically set up the environment.<br><br>3. Data Preparation Scripts: If the paper involves data preprocessing, ensure scripts for these steps are provided along with instructions. Clearly explain how raw data can be transformed into the format used in the experiments.<br><br>4. Results Reproduction: Ensure that scripts to reproduce all tables, figures, and key results presented in the paper are included. Clearly indicate which scripts correspond to which results in the documentation.<br><br>5. Anonymization: Since the paper is under review, ensure that any external links to code or datasets are anonymized appropriately to maintain the double-blind review process integrity.<br><br>By addressing these suggestions, the authors can enhance the reproducibility of their experimental results, which in turn strengthens the credibility and usefulness of their research contributions to the community.<br></p>
                <p><strong>Score:</strong> 0</p>
                <a class="move-to-top" href="#summary-Genuine-question-4">Jump to Summary</a>
            </div>
            
            <div class="review" id="Genuine-question-5">
                <p><strong class="question">Question # 5:</strong> Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material?</p>
                <p><strong class="answer">Answer:</strong> Yes</p>
                <p><strong class="justification">Justification:</strong> We have publicly provided the code on our github repository and details about how to access the datasets on our website.</p>
                <p class="llm_review"><strong>Review:</strong> The answer provided by the authors is consistent with the content in the paper. The paper indeed mentions the availability of the code on GitHub and provides information on accessing the datasets through their website. This indicates that the authors have made efforts to ensure the reproducibility of their experimental results.<br><br>However, a more thorough review of the provided supplementary materials and guidelines reveals that while the authors have made the code and data accessible, the level of detail necessary for "faithfully" reproducing the main experimental results could be further improved. For instance, the paper does not explicitly mention if exact commands and environment settings are provided. Additionally, it is unclear if the authors have included detailed instructions on data access and preparation for all stages of their experiments, including how to access raw data, preprocess data, and generate new datasets.<br><br>To strengthen the reproducibility of the experimental results, I recommend the authors to:<br>1. Ensure that the GitHub repository contains detailed instructions, including the exact command lines and environment needed to reproduce the results.<br>2. Provide a clear and detailed description of data access and preparation in the supplementary materials or on the project's website. This should include how to handle raw, preprocessed, intermediate, and generated data.<br>3. Clarify which experimental results are reproducible with the provided scripts. If any experiments are not included in the reproducibility scripts, clearly state which ones and explain why.<br>4. Consider adding a requirements.txt file or an environment.yml file in the GitHub repository to simplify the setup of the environment needed to run the experiments.<br>5. Verify that all links to data, code, and supplementary material remain accessible and are correctly anonymized (if submission anonymity is required).<br><br>By addressing these suggestions, the authors would enhance the clarity of their reproducibility claims and make it easier for others to verify and build upon their work.<br></p>
                <p><strong>Score:</strong> 1</p>
                <a class="move-to-top" href="#summary-Genuine-question-5">Jump to Summary</a>
            </div>
            
            <div class="review" id="Genuine-question-6">
                <p><strong class="question">Question # 6:</strong> Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results?</p>
                <p><strong class="answer">Answer:</strong> Yes</p>
                <p><strong class="justification">Justification:</strong> We have explained the experimental settings or details in Section 3.2: Experiments. Additional details can be found in the Meta-Album GitHub repository.</p>
                <p class="llm_review"><strong>Review:</strong> Explanation: The answer provided by the authors mentions that the experimental settings or details are explained in Section 3.2 and that additional details can be found in the Meta-Album GitHub repository. However, the justification lacks specificity regarding the types of details provided and does not address whether all the necessary pieces of information needed to understand the results thoroughly are present. For example, it doesn't explicitly confirm whether all training and test details, including data splits, hyperparameters, the type of optimizer, and how hyperparameters were chosen, are clearly provided.<br><br>To ensure a comprehensive review, the authors should have detailed whether these elements are explicitly addressed in the paper or supplementary materials. Just mentioning the section and an external repository for further details is insufficient to ascertain the completeness of the experimental setup description.<br><br>Constructive and Actionable Suggestions:<br>1. Provide a brief summary within the paper of all critical experimental setup details, including data splits, hyperparameters, type of optimizer, and the methodology for choosing hyperparameters. This helps readers quickly grasp the setup without needing to consult external sources.<br>2. If certain information is too voluminous or detailed for the main text, consider including it in an appendix or supplementary material, ensuring it is easily accessible and clearly referenced from the main text.<br>3. Ensure the GitHub repository mentioned for additional details is well-organized and contains clear documentation on experimental settings to facilitate reproduction of results. Mentioning it is beneficial, but it should not replace the need for including critical details within the paper or its immediate supplements.<br>4. For transparency and reproducibility, explicitly state within the paper what information can be found in the GitHub repository and provide direct links to specific files or documentation sections relevant to the experimental setup.<br></p>
                <p><strong>Score:</strong> 0</p>
                <a class="move-to-top" href="#summary-Genuine-question-6">Jump to Summary</a>
            </div>
            
            <div class="review" id="Genuine-question-7">
                <p><strong class="question">Question # 7:</strong> Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments?</p>
                <p><strong class="answer">Answer:</strong> Yes</p>
                <p><strong class="justification">Justification:</strong> In figure-2, figure-3, Appendix E: Within Domain Few-shot learning, and Appendix F: Cross-Domain Few-shot learning, we have reported error bars</p>
                <p class="llm_review"><strong>Review:</strong> The authors have provided error bars as part of their experimental results, which is in line with the requirements for reporting statistical significance. Specifically, they mention the inclusion of error bars in figures 2 and 3, as well as in Appendices E and F, covering both within-domain and cross-domain few-shot learning experiments. This approach helps to understand the variability and reliability of the reported results.<br><br>Justification Evaluation:<br>The answer provided by the authors aligns with the content of the paper and the guidelines for reporting statistical significance. They have outlined where in the paper the error bars are reported, ensuring transparency about the variability in their experimental outcomes. The authors' approach satisfies the criteria of detailing the statistical significance of the experiments and adheres to good scientific reporting practices.<br><br>Constructive and Actionable Suggestions:<br>1. While the authors have mentioned the inclusion of error bars, for enhanced clarity, they could explicitly discuss the calculation method of these error bars in the main sections of the paper, not only in the appendices. This will make it easier for readers to understand the basis of the statistical reporting without needing to refer to supplementary material.<br>2. If not already done, the authors should clarify whether these error bars represent standard deviations, standard errors of the mean, or confidence intervals. Explicitly stating this information within the main text will improve the interpretability of the results.<br>3. It would be beneficial if the authors include a brief discussion on any assumptions made during the calculation of error bars, such as the assumption of normally distributed errors. This transparency is crucial for readers to properly evaluate the significance of the reported results.<br>4. For future work or extensions of this dataset, considering the presentation of results using other statistical significance measures, such as p-values or effect sizes, could further enhance the depth of the analysis. This would provide a more comprehensive understanding of the statistical significance of the differences observed in the experiments.<br><br>Overall, the authors have met the basic requirement by reporting error bars, which is essential for assessing the reliability and significance of their experimental results. Incorporating the above suggestions could further strengthen the paper's statistical reporting and overall quality.<br></p>
                <p><strong>Score:</strong> 1</p>
                <a class="move-to-top" href="#summary-Genuine-question-7">Jump to Summary</a>
            </div>
            
            <div class="review" id="Genuine-question-8">
                <p><strong class="question">Question # 8:</strong> For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments?</p>
                <p><strong class="answer">Answer:</strong> Yes</p>
                <p><strong class="justification">Justification:</strong> We have provided details about compute resources used in Section 3.2: Experiments, Appendix E: Within Domain Few-shot learning, and Appendix F: Cross-Domain Few-shot learning</p>
                <p class="llm_review"><strong>Review:</strong> Justification: While the authors mention providing details about compute resources in several sections of the paper, the specifics mentioned in the given answer are not as comprehensive or explicit as needed for complete reproducibility. The provided information in the given answer lacks detail regarding the actual hardware specifications (e.g., model of GPU, CPU details, amount of RAM) and does not mention execution times for experiments except in the context of meta-training, meta-validation, and meta-test phases in Table 17, which still does not offer a complete picture of the total compute requirements.<br><br>Constructive and actionable suggestions for the authors:<br>1. Include specific hardware configurations for all experiments, such as the type of GPU or CPU used, the number of cores, and the amount of RAM available.<br>2. Provide detailed execution times for each experimental setup mentioned in the paper, not just the meta phases. This would be beneficial for researchers attempting to replicate your results or use your methodology for related work.<br>3. If cloud resources were utilized, specify the provider (e.g., AWS, Google Cloud, Azure) and the configuration of the virtual machines or services employed.<br>4. For experiments requiring significant computational resources, discuss potential bottlenecks and suggest alternative configurations that might reduce compute time or resource requirements.<br>5. Include any software dependencies, along with version numbers, that are crucial for reproducing the experiments. This is especially important if specific libraries or frameworks have a substantial impact on performance.<br><br>By addressing these points, future readers and researchers will have a clearer understanding of what is required to replicate the experiments and potentially extend upon your work, enhancing the paper's value and applicability.<br></p>
                <p><strong>Score:</strong> 0</p>
                <a class="move-to-top" href="#summary-Genuine-question-8">Jump to Summary</a>
            </div>
            
            <div class="review" id="Genuine-question-9">
                <p><strong class="question">Question # 9:</strong> Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?</p>
                <p><strong class="answer">Answer:</strong> Yes</p>
                <p><strong class="justification">Justification:</strong> We completely comply with the NeurIPS Code of Ethics</p>
                <p class="llm_review"><strong>Review:</strong> The authors' confirmation of compliance with the NeurIPS Code of Ethics is succinct and directly addresses the question. Given that there's no detailed explanation required for an affirmative answer (Yes) in this context, the authors' response appears appropriate.<br><br>However, it's important to critically evaluate the provided research and the ethics statement. Based on the detailed presentation of the "Meta-Album" research project, including data preparation, dataset descriptions, and intention for community expansion and inclusivity, it seems the authors have made a conscious effort to adhere to ethical guidelines. These include considerations around dataset licensing, the open invitation for community contributions, and clear acknowledgment of data sources, which align with ethical transparency and fairness.<br><br>Nonetheless, an actionable suggestion for improvement would be for the authors to provide a brief description of how they ensure ethical compliance, particularly in handling data responsibly, ensuring privacy where applicable (even if indirectly, by adherence to dataset licenses already addressing such concerns), and fostering inclusivity in community contributions. An expanded ethics statement could detail specific practices adopted in the research to ensure fairness, respect, transparency, and accountability in accordance with the NeurIPS Code of Ethics.<br></p>
                <p><strong>Score:</strong> 1</p>
                <a class="move-to-top" href="#summary-Genuine-question-9">Jump to Summary</a>
            </div>
            
            <div class="review" id="Genuine-question-10">
                <p><strong class="question">Question # 10:</strong> Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed?</p>
                <p><strong class="answer">Answer:</strong> Yes</p>
                <p><strong class="justification">Justification:</strong> There are no negative societal impacts. Rather, this meta-dataset can foster progress in the fields of few-shot learning and meta-learning. We have added “recommended use” in Section 1.3.</p>
                <p class="llm_review"><strong>Review:</strong> The response from the authors is accurate with the provided content of the paper. The Meta-Album meta-dataset is primarily designed to support research in few-shot learning, meta-learning, and related areas. It provides a resource that could enable advancements in automated machine learning, which is fundamentally beneficial for society by potentially reducing the need for large datasets and extensive computational resources, thereby democratizing access to machine learning capabilities.<br><br>Justification:<br>- The paper clearly outlines the positive societal impacts, particularly in advancing research in few-shot learning and meta-learning. These are areas of machine learning research that have the potential to make learning algorithms more efficient and accessible.<br>- Considering the nature of the dataset and its applications, direct negative societal impacts are not apparent. The dataset itself is a tool for research rather than an application with direct societal interaction, which limits its immediate negative consequences.<br><br>However, a more in-depth analysis or discussion of potential negative impacts could be beneficial, even for foundational research datasets. For foundational research, it can be challenging to predict all future applications and potential misuse. Still, acknowledging this complexity and proposing general considerations or guidelines for ethical use and further development could enhance the paper's discussion on societal impacts.<br><br>Constructive and actionable suggestions:<br>1. Ethical Usage Guidelines: The authors could include a brief section discussing ethical considerations or guidelines for using the dataset. This could cover general principles to encourage responsible use.<br>2. Future Applications Discussion: Explore potential future applications of models developed using the dataset, both positive and negative. This can help to identify areas where ethical considerations or mitigation strategies are particularly relevant.<br>3. Engagement with Ethical Research: Suggest ways the research community could engage with ethics researchers to explore the longer-term societal impacts of advancements in few-shot learning and meta-learning. This interdisciplinary engagement could help in identifying potential risks not immediately apparent to those focused on technical development.<br>4. Transparency and Reproducibility: Emphasize the importance of transparency and reproducibility in research using the dataset, as these principles are fundamental to ensuring that potential societal impacts (positive or negative) can be accurately assessed and understood by the broader community.<br></p>
                <p><strong>Score:</strong> 1</p>
                <a class="move-to-top" href="#summary-Genuine-question-10">Jump to Summary</a>
            </div>
            
            <div class="review" id="Genuine-question-11">
                <p><strong class="question">Question # 11:</strong> Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)?</p>
                <p><strong class="answer">Answer:</strong> Yes</p>
                <p><strong class="justification">Justification:</strong> Indeed, we are releasing our datasets with proper license and terms of use. We have also provided recommended usage of these datasets.</p>
                <p class="llm_review"><strong>Review:</strong> The answer provided by the authors regarding safeguards for responsible release lacks sufficient detail on specific measures implemented to prevent misuse of the data, especially considering the broad range and sensitivity of domains covered by the Meta-Album dataset. While mentioning the release under proper licenses and recommended usage provides a starting point, it does not fully address the potential risks associated with misuse, especially given the variety of data encompassing sensitive areas like human actions and medical images (microscopy domain).<br><br>Constructive and Actionable Suggestions:<br>1. Provide Detailed Data Curation Process: Elaborate on the data curation process to ensure sensitive or personally identifiable information is not included in the dataset. This is particularly pertinent for domains involving human subjects.<br><br>2. Implement Usage Guidelines: Develop and include clear guidelines for the ethical use of the dataset to guide researchers on acceptable uses and discourage misuse. These guidelines should be easily accessible and prominently displayed to all potential users.<br><br>3. Controlled Access: Consider implementing a controlled access model for portions of the dataset that could be more susceptible to misuse. This process could include an application where users outline their intended use of the data and agree to terms of responsible usage.<br><br>4. Ethical Review and Risk Assessment: Document any ethical reviews or risk assessments conducted during the dataset creation process. Sharing insights from these assessments can help users understand potential ethical considerations and how they were meditated.<br><br>5. Community Engagement: Engage with the broader research community to continuously assess the dataset's impact. Encourage users to report any ethical concerns or misuse cases and be prepared to act on these reports to mitigate any harmful consequences.<br><br>By addressing these suggestions, the authors can strengthen the safeguards around the responsible release of the Meta-Album dataset, mitigating potential risks and encouraging ethical research practices.<br></p>
                <p><strong>Score:</strong> 0</p>
                <a class="move-to-top" href="#summary-Genuine-question-11">Jump to Summary</a>
            </div>
            
            <div class="review" id="Genuine-question-12">
                <p><strong class="question">Question # 12:</strong> Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected?</p>
                <p><strong class="answer">Answer:</strong> Yes</p>
                <p><strong class="justification">Justification:</strong> We are releasing our datasets with proper license, we are also mentioning the original licenses for the original datasets in Appendix B: License information of Meta-Album datasets</p>
                <p class="llm_review"><strong>Review:</strong> The authors of the paper have explicitly stated their adherence to proper licensing practices concerning the datasets used in their research, as mentioned in their response. The fact that they have dedicated a section (Appendix B) to license information of Meta-Album datasets demonstrates their commitment to crediting the original owners and respecting the terms of use. This section appears to include details about the licenses, ensuring transparency and proper attribution for the used datasets.<br><br>However, a more thorough review could enhance clarity and adherence to best practices:<br>1. Explicit Mention of All Licenses: Ensure every dataset mentioned in the paper is accompanied by a clear statement of its license, both within the main text (when first introduced) and in the dedicated appendix.<br>2. Versioning and URLs: Although the mentioning of licenses is in place, adding specific versions of the datasets and direct URLs where the licenses and datasets can be viewed would improve reproducibility and accountability. This is crucial since datasets often undergo updates that might have licensing implications.<br>3. Clarification on Derived Assets: If any datasets were modified or combined to create new datasets (which seems likely given the nature of Meta-Album), clarify the licensing of these derived assets. It's essential to ensure that the new datasets' creation and distribution do not violate the original terms.<br>4. License for Redistribution: If the authors are redistributing existing datasets, either in their original form or a modified version, it's crucial to ensure that the original licenses permit such redistribution.<br><br>In summary, while the authors have taken significant steps to ensure proper credit and adherence to licensing terms, further detailing and clarification could enhance compliance and serve as a robust model for best practices in dataset usage and distribution within the academic community.<br></p>
                <p><strong>Score:</strong> 1</p>
                <a class="move-to-top" href="#summary-Genuine-question-12">Jump to Summary</a>
            </div>
            
            <div class="review" id="Genuine-question-13">
                <p><strong class="question">Question # 13:</strong> Are new assets introduced in the paper well documented and is the documentation provided alongside the assets?</p>
                <p><strong class="answer">Answer:</strong> Yes</p>
                <p><strong class="justification">Justification:</strong> We have properly documented our new datasets using meta-data files and datasheets for datasets (provided in the appendices). We have also designed a website for users to easily get all the datasets and related information</p>
                <p class="llm_review"><strong>Review:</strong> The given answer aligns with the paper content regarding the introduction and documentation of new assets, namely the Meta-Album meta-dataset. The authors have indeed detailed their methodology in documenting the datasets through meta-data files and datasheets as stated, which are presented in the appendices. Additionally, the creation of a dedicated website for accessing the datasets and associated information further supports their claim of thorough documentation. The paper thereby adheres to the guidelines for asset documentation by providing structured information on the datasets included in the Meta-Album, including details on their preparation, quality control measures, and how users can access and utilize these assets.<br><br>Suggestions:<br>1. For further improvement, the authors could include explicit information on the licensing for each dataset included in the Meta-Album, ensuring users understand the permissions and restrictions for usage. This could be added directly in the paper text for quick reference and in the documentation provided on the website.<br>2. It would be beneficial to discuss any limitations or biases inherent in the datasets included in the Meta-Album meta-dataset. This transparency can aid researchers in properly interpreting their experimental results and guide future work in addressing these limitations.<br>3. While the provided website is a valuable resource, ensuring it remains updated with the latest information and datasets will be crucial. Adding a section on the site for user feedback or contributions could further enhance the Meta-Album as a community-driven asset.<br>4. Clarification on how consent was obtained (if applicable) for any data derived from human subjects or where copyright considerations apply would be valuable in aligning with ethical research standards.<br></p>
                <p><strong>Score:</strong> 1</p>
                <a class="move-to-top" href="#summary-Genuine-question-13">Jump to Summary</a>
            </div>
            
            <div class="review" id="Genuine-question-14">
                <p><strong class="question">Question # 14:</strong> For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)?</p>
                <p><strong class="answer">Answer:</strong> nan</p>
                <p><strong class="justification">Justification:</strong> This does not apply on our research as we are not doing any crowdsourcing experiments</p>
                <p class="llm_review"><strong>Review:</strong> The answer provided by the authors is accurate and consistent with the content of the paper. The paper introduces Meta-Album, a meta-dataset aimed at facilitating research in few-shot learning, meta-learning, and similar domains within computer vision, specifically focusing on image classification. The work predominantly involves curating and processing existing datasets rather than conducting crowdsourcing experiments or research with human subjects. Hence, the requirements for including instructions, screenshots, and compensation details for participants do not apply to this study.<br><br>Constructive suggestions for improvement could include:<br><br>1. Clarify in the methodology or ethical considerations section that the study did not involve primary data collection from humans, underscoring the secondary nature of data use for transparency.<br><br>2. While the current answer is sufficient, future versions of related work could benefit from a brief mention or disclaimer regarding the ethical considerations around data use, even if the datasets are publicly available or derived from existing sources. This is especially relevant as ethical guidelines and standards for AI research continue to evolve.<br><br>3. For readers less familiar with the distinction between types of data collection and analysis, a simple sentence acknowledging awareness of ethical standards for research involving human subjects (even to confirm that such standards were not applicable in this case) might add value to the presentation of the work.<br></p>
                <p><strong>Score:</strong> 1</p>
                <a class="move-to-top" href="#summary-Genuine-question-14">Jump to Summary</a>
            </div>
            
            <div class="review" id="Genuine-question-15">
                <p><strong class="question">Question # 15:</strong> Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained?</p>
                <p><strong class="answer">Answer:</strong> nan</p>
                <p><strong class="justification">Justification:</strong> This does not concerns us as we are not dealing with human subjects in our research.</p>
                <p class="llm_review"><strong>Review:</strong> The authors' justification for not addressing potential risks incurred by study participants and not obtaining Institutional Review Board (IRB) approvals based on the pretext of "not dealing with human subjects" is inconsistent with the comprehensive nature of preparing a dataset, such as Meta-Album, described in the paper. Even though the direct involvement of human participants in the creation of the Meta-Album dataset might be minimal or not applicable, the downstream applications of such datasets could potentially involve risks related to privacy, bias, fairness, and use in sensitive applications. Therefore, the ethical implications and potential risks associated with the dataset's usage should have been considered, even if traditional IRB approval was not directly required.<br><br>Constructive and actionable suggestions:<br>1. Ethical Consideration Section: The authors should consider adding a dedicated section on ethical considerations and potential risks related to the use of their dataset. This could include discussions on privacy, bias, fairness, and the intended as well as unintended uses of the dataset.<br>2. Dataset Usage Guidelines: Offer guidelines or recommendations on how the dataset should be ethically used, including any limitations on its use in certain types of research or applications.<br>3. Bias and Fairness Analysis: Conduct and present an analysis of potential biases within the dataset and their implications for fairness in machine learning applications leveraging the Meta-Album.<br>4. Community Engagement: Encourage and facilitate the engagement of the broader research community in discussions about ethical use and potential risks associated with the dataset. This could be achieved through workshops, forums, or participatory design sessions.<br>5. Iterative Ethics Review: Consider establishing an ongoing review process for ethical considerations tied with the dataset’s evolution. As the dataset grows and diversifies, new ethical considerations may arise that warrant attention and mitigation strategies.<br></p>
                <p><strong>Score:</strong> 0</p>
                <a class="move-to-top" href="#summary-Genuine-question-15">Jump to Summary</a>
            </div>
            
        
        
    </div>

    <a class="button button-bottom" href="https://docs.google.com/forms/d/e/1FAIpQLSfRIDkcXFbsOrR09j4qA1MlG4Rfir2lPD_u9YC4eqKBJ8tHkw/viewform?usp=pp_url&entry.1830873891=TWV0YS1BbGJ1bTogTXVsdGktZG9tYWluIE1ldGEtRGF0YXNldCBmb3JGZXctU2hvdCBJbWFnZSBDbGFzc2lmaWNhdGlvbg==" target="_blank">Click to submit post submission survey</a>

</div>

</body>
</html>