Question,Answer,Justification,Guidelines,Review,Correctness_Score
Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope?,Yes,Our main claims are listed in section 1 and highlight this paper's contributions.,"• The answer NA means that the abstract and introduction do not include the claims made in the paper. • The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. • The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. • It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. ","Justification Review:
The justification provided by the authors for the question about the main claims accurately reflecting the paper's contributions and scope is somewhat generic and does not directly address the alignment between the claims and the actual contributions of the paper. However, based on the entire content of the paper, it is clear that the abstract and introduction sections do accurately highlight the main contributions and scope, despite the authors' justification not explicitly stating this.

- The paper claims to address issues with Neural Architecture Search (NAS) in Spatio-Temporal Graph Neural Networks (STGNNs), specifically the integration of hyperparameters into the NAS framework and the reduction of the STGNN search space. These claims are substantiated through the development of a disentangled framework for understanding and simplifying architecture search.
- The abstract outlines the contributions, including the proposal of a disentangled framework containing designs for spatial/temporal modules, spatio-temporal order, and skip connection, a substantial exploration of the hyperparameter setting, and thorough experiments to derive fundamental design principles.
- The introduction provides context and motivation for these contributions by discussing the challenges in designing STGNNs, the importance of architecture and hyperparameter optimization, and the benefits of the proposed disentangled framework for understanding Spatio-temporal architectures.

Constructive Suggestions:
1. **Clarify Claims and Contributions**: The authors are encouraged to more explicitly correlate each claim made in the abstract and introduction with specific sections or findings within the body of the paper. This can help reviewers and readers quickly verify the claims.

2. **Highlight Novelty and Impact**: Strengthen the wording around the novelty and potential impact of the contributions, especially how the disentangled framework and understanding of hyperparameters might advance the field of STGNNs beyond existing NAS methodologies.

3. **Discuss Limitations and Assumptions**: While the guidelines suggest it's fine to include aspirational goals, it would also be beneficial for the authors to briefly discuss any limitations or assumptions underlying their approach directly in the introduction to set realistic expectations.

4. **Comparison with Related Work**: Expand on how this work differentiates from existing NAS methods in the context of STGNNs within the introduction. This can provide a clearer scope of the paper's contributions in relation to the current state-of-the-art.

5. **Future Work Directions**: Briefly mention potential future work directions or open questions based on the findings, which could indicate to reviewers the paper's contributions towards advancing the field's knowledge frontier.

Overall, the paper's abstract and introduction do set appropriate expectations for the contributions and scope of the work, even though the authors' justification for the alignment could be more specific.",1
Does the paper discuss the limitations of the work performed by the authors?,Yes,"We have discussed the potential limitations in section 6, including the application domain and considered temporal modeling methods.","• The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. • The authors are encouraged to create a separate """" section in their paper. • The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. • The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. • The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. • The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. • If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. • While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. ","Justification: The paper provides a comprehensive review and novel contributions to the field of Spatio-Temporal Graph Neural Networks (STGNNs). It proposes a disentangled framework to simplify Neural Architecture Search (NAS) for STGNNs, addresses the issue of hyperparameter integration in NAS, and identifies a reduced and efficient search space. However, the response provided to the question regarding the discussion of limitations within the paper is not fully supported by the content presented in the provided excerpts.

The response indicates that limitations are discussed in section 6, focusing on application domains and considered temporal modeling methods. Upon a detailed review of the content, section 6 or a discussion specifically labeled as ""Limitations"" was not identified in the provided excerpts. It's essential for the review to critically assess whether the paper indeed discusses the limitations as suggested or if there could be an oversight.

Additionally, acknowledging limitations is crucial for the scientific integrity of a paper. It provides a clearer perspective for readers on the research's boundaries and areas for future improvement. While the paper outlines a range of contributions and experiments to address issues within STGNN NAS, a structured and explicit discussion regarding the limitations of their approach, assumptions made, scope of the claims, computational efficiency, and potential ethical considerations such as privacy and fairness is essential but seems to be indirectly addressed or not fully covered in the provided excerpts.

Constructive suggestions:
1. Revise the manuscript to include a dedicated section or paragraphs that explicitly discuss the limitations of the work. This should cover not only the application domain and temporal modeling methods but also any assumptions made, potential limitations in the generalizability of the findings across different domains or datasets, computational requirements and scalability, and ethical considerations.

2. Reflect on the robustness of the results, particularly under different assumptions or violations of those assumptions. Discuss how such scenarios might affect the applicability and performance of the proposed framework.

3. Consider discussing the scalability of the proposed NAS approach in STGNNs concerning different dataset sizes and the computational resources required. This will provide a more comprehensive understanding of the practical applications of the work.

4. Address potential ethical considerations, especially if the technology could have broader implications that might raise concerns related to privacy, fairness, or other societal impacts.

5. Ensure that the limitations and potential future work suggestions are grounded in the experiments and findings detailed in the manuscript, providing a pathway for advancing the field.",0
"For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof?",Yes,We have discussed the assumptions in the section 4 when we introduce graph characteristics.,"• The answer NA means that the paper does not include theoretical results. • All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced. • All assumptions should be clearly stated or referenced in the statement of any theorems. • The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. • Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. • Theorems and Lemmas that the proof relies upon should be properly referenced. ","Justification:
The question regarding the provision of full sets of assumptions and complete/correct proofs for all theoretical results has been answered affirmatively by the authors, citing discussions in section 4 related to graph characteristics. However, upon thorough examination of the presented content, this claim does not align entirely as the paper primarily focuses on the practical application and experimentation surrounding Spatio-Temporal Graph Neural Networks (STGNNs) and their architecture search. The document predominantly discusses the disentangled framework for architecture design, the significance of various hyperparameters, and the methodology for evaluating architectures on spatio-temporal tasks. Though it refers to empirical studies and presents a framework based on observed principles, the paper falls short of providing theoretical results that would require assumptions to be explicitly stated or formal proofs to be offered.

Constructive Suggestions:
1. Clarify Definitions: If the paper presents any theoretical results, ensure that these are clearly defined and distinguished from empirical findings. This could involve stating assumptions explicitly in a separate subsection dedicated to theoretical considerations.
2. Proof Details: For any theoretical claims, provide detailed proofs or sketch proofs in the main text and offer full proofs in the supplementary material. This is crucial for the transparency and verifiability of the theoretical claims.
3. Reference Supporting Theorems: If the paper relies on foundational theorems or well-known results from the literature, make sure to reference these appropriately and discuss how they support the novel contributions of your work.
4. Supplement Material: Consider including a supplemental document that hosts all the mathematical rigor behind the empirical observations, even if the paper's main focus is on practical applications. This could be particularly useful for researchers looking to build on your theoretical foundations.
5. Revision of Claims: Re-examine the paper to ensure that any claim of providing full assumptions and complete proofs for theoretical results is accurate. If theoretical results are not the paper's focus, revise the statement to reflect more accurately the nature of the contributions (e.g., empirical findings, framework proposal, performance evaluation).",0
Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)?,Yes,"We discuss the experiment settings in section 4, section 5 and appendix B, C, D, E including dataset, baseline, implementation and results. We also include our code in the github link https://github.com/AutoML-Research/SimpleSTG.","• The answer NA means that the paper does not include experiments. • If the paper includes experiments, a No answer to this question will not be perceived well by the reviewers: Making the paper reproducible is important, regardless of whether the code and data are provided or not. • If the contribution is a dataset and/or model, the authors should describe the steps taken to make their results reproducible or verifiable. • Depending on the contribution, reproducibility can be accomplished in various ways. For example, if the contribution is a novel architecture, describing the architecture fully might suffice, or if the contribution is a specific model and empirical evaluation, it may be necessary to either make it possible for others to replicate the model with the same dataset, or provide access to the model. In general. releasing code and data is often one good way to accomplish this, but reproducibility can also be provided via detailed instructions for how to replicate the results, access to a hosted model (e.g., in the case of a large language model), releasing of a model checkpoint, or other means that are appropriate to the research performed. • While NeurIPS does not require releasing code, the conference does require all submissions to provide some reasonable avenue for reproducibility, which may depend on the nature of the contribution. For example (a) If the contribution is primarily a new algorithm, the paper should make it clear how to reproduce that algorithm. (b) If the contribution is primarily a new model architecture, the paper should describe the architecture clearly and fully. (c) If the contribution is a new model (e.g., a large language model), then there should either be a way to access this model for reproducing the results or a way to reproduce the model (e.g., with an open-source dataset or instructions for how to construct the dataset). (d) We recognize that reproducibility may be tricky in some cases, in which case authors are welcome to describe the particular way they provide for reproducibility. In the case of closed-source models, it may be that access to the model is limited in some way (e.g., to registered users), but it should be possible for other researchers to have some path to reproducing or verifying the results. Open Access to Data and Code","Justification Review:
The paper provides a comprehensive exposition of the methodologies, experimental settings, dataset details, implementation information, and results across the main text and appendices, which collectively enable the reproducibility of the main experimental results. The inclusion of a GitHub link to the source code significantly enhances the reproducibility aspect. The detailed explanation across sections 4, 5, and appendices B, C, D, E, including but not limited to dataset descriptions, baseline comparisons, parameter settings, and insights into the architectural choices and hyperparameter implications, offers a clear roadmap for replicating the study's findings. Additionally, the explicit mention of the datasets used (e.g., PeMS datasets) and the problem setting facilitates a straightforward reconstruction of the experimental setup. These elements, in conjunction, address the NeurIPS guideline requirements for reproducibility appropriately.

Constructive Suggestions:
1. **Data Accessibility:** While the GitHub link is provided, ensuring the dataset links within the repository are functioning and up-to-date will further assist in replication efforts. Explicitly stating any preprocessing steps or dataset splits used would be valuable.

2. **Dependencies and Environment Setup:** Including a requirements.txt file or an equivalent to specify the exact versions of libraries and tools used could prevent issues related to software version discrepancies.

3. **Baseline Implementations:** If any baseline methods were reimplemented for the study, providing those implementations or detailing any modifications made to existing implementations would enhance clarity.

4. **Additional Implementation Details:** Offering more insight into any challenges faced during implementation, how they were resolved, and tips for efficient experimentation could be beneficial for researchers attempting to reproduce or extend the work.

5. **Expanded Results:** Sharing raw results data in addition to summary statistics might enable more detailed analyses by other researchers, such as further statistical testing or meta-analysis in future works.

Overall, the authors have met the NeurIPS reproducibility requirement effectively by providing a detailed methodology, sharing code, and ensuring clear communication of experimental settings and results.",1
"Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material?",Yes,"All the data and code are open access. The dataset information is mentioned in section 4, 5, Appendix B and the code is available in github https://github.com/ AutoML-Research/SimpleSTG.","• The answer NA means that paper does not include experiments requiring code. • Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details. • While we encourage the release of code and data, we understand that this might not be possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark). • The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details. • The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc. • The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why. • At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). • Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. ","The answer provided is consistent with the content of the paper reviewed. The authors have clearly stated that the code for their work is available on GitHub at the specified URL, which satisfies the requirement for open access to code with sufficient instructions to faithfully reproduce the main experimental results. This submission aligns well with NeurIPS guidelines on code and data submission, which encourage but do not mandate the release of code and data.

However, to ensure the most thorough and helpful review, here are some additional, constructive suggestions for the authors regarding the code and data accessibility:

1. **Documentation:** Ensure the GitHub repository contains detailed documentation, including a README file with step-by-step instructions on how to set up the environment, install dependencies, and execute the scripts to reproduce the experiments.

2. **Environment Details:** Include an environment file (e.g., a `requirements.txt` or `environment.yml` file for Python) specifying the exact versions of the libraries and tools used. This will help in creating an identical environment to prevent potential compatibility issues.

3. **Data Preparation Scripts:** Although the paper mentions the datasets used and that they are publicly available, it would be beneficial to include scripts for data preprocessing to ensure that users can reproduce the results from the exact same data format as used in the experiments.

4. **Experiment Reproducibility:** Ensure that the scripts provided cover all the main experiments presented in the paper. If any experimental results cannot be reproduced with the provided code due to resource constraints or privacy issues, explicitly mention this and provide simulated or smaller-scale versions of these experiments if possible.

5. **Contact Information:** Provide a way for readers to reach out for help, such as an issues section in the GitHub repository or a contact email. This can be invaluable for dealing with unforeseen issues in reproducing the results.

By addressing these points, the authors can further increase the accessibility and utility of their code and data, enhancing the paper's contribution to the community.",1
"Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results?",Yes,Hyperparameter sampling is one of our method designs as explained in section and 5. We also specify the training and test details in the same sections and appendix B.,"• The answer NA means that the paper does not include experiments. • The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. • The full details can be provided either with the code, in appendix, or as supplemental material. ","The answer provided by the authors is consistent with the content of the paper. The paper does extensively discuss training and test details, including data splits, hyperparameters and how they were chosen, optimizer types, etc., throughout various sections and the appendices. This detailed description enables readers to understand the experimental setup and replicate the study if desired. The inclusion of such details is crucial for the transparency and reproducibility of the research, and the authors have adhered to this by providing comprehensive information. Additionally, the paper mentions the availability of the code, which further aids in understanding the implementation details.

Constructive and Actionable Suggestions:
1. While the information provided is extensive, ensuring that the main text succinctly outlines the most critical experimental parameters and referring readers to the appendices for more exhaustive descriptions might enhance readability and immediate comprehension.
2. Consider providing a summarized table or framework in the main text that encapsulates elemental training and testing configurations, making it easier for readers to grasp the experimental set-up without necessarily diving into the appendices.
3. Ensure the GitHub repository (if not already) contains detailed comments and documentation, especially regarding the hyperparameter selection process and any scripts used for automatic hyperparameter tuning or optimization, to facilitate easier replication and adaptation by other researchers.
4. While the appendices provide detailed information, ensuring that they are organized in a manner that is easy to navigate and reference from the main text can further assist in understanding the setup and results.
5. Lastly, the authors could consider elaborating on the decision-making process behind certain hyperparameter choices or data split ratios if derived from empirical observations or prior studies, providing additional insights into their research methodology.",1
Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments?,Yes,Our main experiments in section 4 and 5 all include variance as error bars. The experiments are based on multiple runs with mean and variance calculated.,"• The answer NA means that the paper does not include experiments. • The authors should answer ""Yes"" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. • The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions). • The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.) • The assumptions made should be given (e.g., Normally distributed errors). • It should be clear whether the error bar is the standard deviation or the standard error of the mean. • It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified. • For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates). • If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. ","Justification: While the authors claim that error bars, specifically variance, are included in the main experiments to denote statistical significance, the provided content does not explicitly detail how these error bars were computed, nor does it address the considerations outlined in the review guidelines. The guidelines suggest a thorough explanation of the calculation method for error bars, assumptions made (e.g., normally distributed errors), and whether the error bar represents standard deviation or standard error of the mean. Without this level of detail, it's challenging to assess the robustness and reliability of the experimental results fully.

Constructive and Actionable Suggestions:
1. Clearly state the types of variability that the error bars capture (e.g., variations across train/test splits, initialization randomness, or parameter sampling randomness). This helps in understanding the sources of uncertainty in the experiments.
2. Offer a detailed explanation of how the error bars were calculated. If a specific statistical method or library function was used, please mention this explicitly.
3. Clarify the assumptions made in the calculation of error bars, such as the assumption of normally distributed errors. If assumptions are made, justify their validity in the context of your experiments.
4. Specify whether the error bars represent the standard deviation or the standard error of the mean. If possible, consider providing 2-sigma error bars for a more conservative representation of confidence intervals.
5. For experiments where error bars are not symmetric due to the nature of the data distribution, explore presenting them in a manner that accurately reflects this asymmetry. This may involve indicating the range or using other statistical measures that account for the distribution's shape.
6. Ensure that any sections of the paper mentioning the inclusion of error bars or statistical significance tests also reference the specific figures or tables where these can be visually inspected to enhance reader comprehension.
7. Consider including a subsection in the methodology or experimental setup section dedicated to explaining the statistical analysis approach in detail. This addition would greatly benefit readers seeking to understand the statistical underpinnings of your findings.

By addressing these points, the authors can significantly enhance the clarity and reliability of the experimental results reported in the paper.",0
"For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments?",Yes,"In section 5, we reported the GPU hours that are required to generate reasonable answers w.r.t. multiple baselines.","• The answer NA means that the paper does not include experiments. • The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. • The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. • The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper). Code of Ethics","Justification: While the paper does provide information on the GPU hours required for the NAS method comparison, it lacks detailed specifics regarding the type of computational resources involved (e.g., GPU model, CPU specifications, memory capacity, etc.), which are essential for reproducibility. This detail is necessary to fully understand the computational cost and to reproduce the experiments under similar conditions. Moreover, there is no clear mention of whether these reported GPU hours apply to all experiments or specific ones, nor is there detailed information on the compute resources needed for each individual experiment. Lastly, the paper does not disclose if additional compute was required beyond what is reported for the experiments, such as for preliminary tests or failed experiments.

Constructive Suggestions:
1. **Detailed Computational Resources**: Provide more specific details about the computational resources used for the experiments, including the type and model of GPUs, CPU specifications, available memory, and any use of cloud computing services.
2. **Breakdown of Compute Requirements**: Offer a breakdown of the computational resources and time required for each experiment or set of experiments. This would help in understanding the computational cost associated with different parts of the research.
3. **Additional Compute Disclosure**: If there was additional computational work done that is not directly reported in the paper (e.g., for model development, parameter tuning, failed experiments), it would be beneficial to disclose this to give readers a fuller picture of the compute requirements for the project.
4. **Execution Environment Description**: Include a description of the software environment (e.g., operating system, programming languages, and versions of key libraries or frameworks) used to run the experiments. This aids in reproducing the results with the same or similar software dependencies.
5. **Guide for Replication**: Provide a more detailed guide or supplementary material for replicating the experiments, including scripts for dataset processing, model training, and evaluation. This could potentially include Dockerfiles or environment configuration files to ease the setup process for those attempting to replicate the studies.

These suggestions aim to improve the clarity and reproducibility of the computational experiments described in the paper, adhering to good scientific practice by enabling others to validate findings through replication.",0
"Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?",Yes,We review the code of ethics and our paper conform with it.,"• The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. • If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. • The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). ",Justification for the,0
Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed?,Yes,"We discuss the broader impacts in the section ""Broader Impact Statement"".","• The answer NA means that there is no societal impact of the work performed. • If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. • Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations. • The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. • The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. • If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). ","Justification for Score:
The reviewed paper does not explicitly provide a section titled ""Broader Impact Statement"" nor discusses the potential positive and negative societal impacts as indicated in the author's answer. The content provided in the paper mainly focuses on the technical advancements and methodologies related to Spatio-Temporal Graph Neural Networks (STGNNs) and their application in traffic prediction. While the application in traffic forecasting has inherent societal impacts, such as possibly improving traffic management, reducing congestion, and potentially lowering emissions by optimizing transportation networks, these aspects are not discussed in depth in terms of broader societal implications.

Constructive Suggestions:
1. **Explicitly Address Societal Impact**: Incorporate a section specifically dedicated to discussing both the positive and negative societal impacts of your work on Spatio-Temporal Graph Neural Networks. This section should go beyond the application use case and delve into broader implications, including but not limited to ethical, privacy, and security considerations.

2. **Potential Positive Impacts**: Elaborate on how the improvements in traffic forecasting enabled by your approach could benefit society. For example, discuss how better traffic prediction can lead to more efficient transportation networks, reduced carbon emissions, and decreased time spent in traffic, thereby improving the quality of life. 

3. **Potential Negative Impacts**: Discuss potential negative impacts related to the deployment of your system. For instance, consider the implications of data privacy (given that traffic data might include sensitive information about individuals' location patterns), the potential for systemic biases in predictions, and how inaccurate predictions could lead to negative consequences.

4. **Mitigation Strategies**: Offer suggestions for mitigating any identified negative impacts. This could include approaches to ensuring data privacy, methods to test and remove biases from predictions, and strategies to ensure the reliability of traffic forecasts.

5. **Future Directions**: As you lay out the societal impacts, also discuss areas of future research that could further explore these aspects. Highlighting these areas can help guide the community to address these issues proactively.

These suggestions aim to strengthen the paper by providing a comprehensive view of the work's societal implications, thereby aligning with the conference's expectations for authors to consider the broader impacts of their research.",0
"Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)?",Yes,"We have discussed the details of the used datasets and models in section 4, 5 and appendix B.","• The answer NA means that the paper poses no such risks. • Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. • Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. • We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. Licenses for Existing Assets","Justification provided by the authors does not directly address the specific safeguards for responsible release and prevention of misuse of data or models, as outlined in the question. The reference to sections where datasets and models are discussed does not equate to detailing specific measures taken for safe and responsible release. Addressing concerns about the possible misuse of models, especially those with potential implications for privacy, security, or ethical considerations, requires explicit mention of the safeguards or protocols put in place.

Constructive and actionable suggestions:
1. **Clarification and Explicit Measures**: The authors should clearly articulate any specific measures they have taken to mitigate the risk of misuse associated with their datasets or models. This could include, but is not limited to, access control mechanisms, usage guidelines, or ethical review processes. If such measures have been taken, they should be described explicitly in the paper.

2. **Ethical Considerations**: It would be beneficial if the authors included a dedicated section or paragraph discussing the ethical considerations of their research, particularly focusing on the potential risks for misuse of their models and the data they used. This part should outline any potential negative impacts and how they plan to mitigate these issues.

3. **License and Use Conditions for Datasets and Models**: If the authors are releasing any datasets or models, they should consider associating them with licenses that outline permissible uses or incorporate ethical use clauses. Clarifying the licensing can help ensure responsible use by third parties.

4. **Engagement with Institutional Review Boards (IRB)**: If applicable, the authors should mention any engagement with IRBs or ethics committees regarding their research. This would provide readers with an understanding that the research has undergone scrutiny for ethical considerations.

5. **Community Guidelines**: If the authors are part of a larger research initiative or employing platforms for sharing their models/data, they should adhere to and mention any community guidelines or standards for responsible AI research and development.",0
"Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected?",Yes,"We explicitly mentioned and cited the source of the data used in our paper [13, 1, 10]. These datasets can be accessed on GitHub https://github.com/Davidham3/ ASTGCN/tree/master/data.","• The answer NA means that the paper does not use existing assets. • The authors should cite the original paper that produced the code package or dataset. • The authors should state which version of the asset is used and, if possible, include a URL. • The name of the license (e.g., CC-BY 4.0) should be included for each asset. • For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided. • If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset. • For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. • If this information is not available online, the authors are encouraged to reach out to the asset's creators. ","The authors have adhered to the requirements regarding crediting the creators or original owners of the assets used in their paper. They have cited the original papers [13, 1, 10] that produced the datasets and provided a URL where these datasets can be accessed. Although the specific version of the dataset and the name of the license under which these datasets are released are not explicitly mentioned in the provided justification, this level of detail is not always feasible or required for publicly available datasets commonly used in the research community. The citation and the provision of access information fulfill the basic requirements of crediting the source and respecting terms of use.

However, to improve the completeness of the asset acknowledgment and ensure adherence to any specific licensing terms, the following itemized, constructive, and actionable suggestions are offered to the authors:

1. **Include License Information**: If possible, add the name of the license under which each dataset is released. This information is crucial for ensuring that future researchers understand their rights and responsibilities when using these datasets.

2. **Versioning Details**: If the datasets have multiple versions, specifying which version was used can help in replicating the results and understanding the context of the data better.

3. **Terms of Use**: Briefly mention any terms of use or restrictions associated with the datasets, if applicable. This will ensure that readers are aware of any limitations in using the data for certain types of research or applications.

4. **Contact Original Creators**: If there are any ambiguities regarding the use of the datasets, considering reaching out to the original creators to clarify terms of use, especially if the research involves sensitive or proprietary information.

By addressing these points, the authors can enhance the transparency and reproducibility of their research, ensuring that all assets used are credited appropriately and that their use complies with the original terms and conditions.",1
Are new assets introduced in the paper well documented and is the documentation provided alongside the assets?,Yes,"We have included enough documentation in section 4, 5 and appendix B with respect to our introduced benchmarks.","• The answer NA means that the paper does not release new assets. • Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc. • The paper should discuss whether and how consent was obtained from people whose asset is used. • At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. ","Justification for the score: The provided justification in the review does not sufficiently detail the documentation aspects of the new assets introduced in the paper. While it mentions that documentation is included in sections 4, 5, and Appendix B concerning the introduced benchmarks, it lacks specificity on how these sections cover essential documentation elements such as training details, license information, limitations, and consent for use. This vagueness makes it challenging to assess the completeness and adequacy of the documentation provided alongside the new assets.

Constructive and Actionable Suggestions:

1. Clarify Documentation Details: Enhance the justification by specifying how the documentation provided in sections 4, 5, and Appendix B addresses key documentation components for new assets. This includes detailing the training process, describing any pre-processing steps, specifying the license under which the assets are released, and noting any limitations or biases inherent in the assets.

2. Incorporate Structured Templates: Employ structured templates when documenting new assets. These templates should succinctly capture critical information about the dataset, code, or model introduced in the paper, making it easier for readers and future researchers to understand and reuse the assets.

3. Explicitly Discuss Consent: If the new assets involve data or contributions from individuals, explicitly discuss how consent was obtained. If applicable, include information on ethical considerations and how privacy concerns were addressed.

4. Anonymize Assets for Review: Ensure that any assets linked or included with the submission are appropriately anonymized for the review process. Provide clear instructions on how reviewers can access these anonymized assets without compromising the blind review integrity.

5. Link to Repository: If possible, provide a link to a publicly accessible repository where the assets and their documentation are hosted. Ensure that the repository includes a comprehensive README file that guides users through the assets, their intended use, and any setup or installation requirements.

By addressing these points, the paper can significantly improve the level of detail and transparency regarding the documentation and availability of introduced assets, thereby enhancing reproducibility and fostering further research in the field.",0
"For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)?",Not Applicable,This paper does not involve crowdsourcing nor research with human subjects.,"• The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. • Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper. • According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. ","The answer and justification correctly indicate that the question is not applicable to the content of the paper being reviewed. Upon reviewing the paper's content, it is evident that the described work centers on the development and evaluation of machine learning models specifically for spatio-temporal graph neural networks, with no mention of crowdsourcing experiments, research with human subjects, or any processes that involve human participation in experimentation. Thus, the requirement to include the full text of instructions, screenshots, or details about compensation does not apply to this study.

Constructive and Actionable Suggestions:
Since the answer to the question is correctly marked as N/A based on the paper's focus, there are no specific suggestions related to inclusion of human subject research information. However, to further strengthen the review process and ensure comprehensive assessment, the reviewer can consider addressing the following general aspects if not already done:
1. Verify the thoroughness of experimental design descriptions, ensuring that all relevant details are provided to allow for replicability.
2. Assess whether the paper adequately discusses the potential ethical implications of the proposed algorithmic solution, particularly if the application domain (e.g., traffic prediction) can have broader societal impacts.
3. Ensure that the paper provides a clear explanation of the novelty and contributions in comparison to previous work in the domain, especially in relation to neural architecture search (NAS) techniques and their application in spatio-temporal forecasting tasks.
4. Evaluate the clarity and completeness of the methodology section, including the description of the datasets used, model architecture details, and evaluation metrics.
5. Review the discussion and conclusion sections for insights into the limitations of the current work and potential future directions, contributing to the ongoing discourse in the field. 

These suggestions aim to maintain the high standards of review and contribute positively to the advancement of research in the field of machine learning and spatio-temporal graph neural networks.",1
"Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained?",Not Applicable,This paper does not involve crowdsourcing nor research with human subjects.,"• The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. • Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper. • We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution. • For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.","The answer provided by the authors is consistent with the content of the paper. Based on the extensive description provided, the paper focuses on the development, understanding, and application of Spatio-Temporal Graph Neural Networks (STGNNs) for traffic prediction and does not involve direct human participation, crowdsourcing, or any form of research that would typically warrant Institutional Review Board (IRB) approval. The nature of the research falls within the computational and theoretical domain, analyzing and proposing improvements to architectural search methodologies and hyperparameter understanding in STGNNs. Therefore, the aspects related to IRB approval or potential risks to study participants do not apply.

Suggestions for improvement:
- Although the current research does not involve human subjects, it’s important to mention any secondary implications or ethical considerations related to the application of the proposed models, especially in terms of privacy, data security, or potential misuse in surveillance or monitoring without consent.
- Future work that might involve human subjects or personal data, even indirectly, should clearly state the ethical considerations and necessary compliance with institutional review boards or equivalent ethical review processes.
- As part of the broader impact or future directions sections, it would be valuable for the authors to discuss any potential societal impacts, both positive and negative, that their research or the application of their findings might entail.",1
