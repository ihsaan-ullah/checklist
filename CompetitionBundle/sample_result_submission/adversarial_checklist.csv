Question,Answer,Justification,Guidelines,Review,Correctness_Score
Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope?,No,We haven't mentioned the main claims in the abstract and introduction,"• The answer NA means that the abstract and introduction do not include the claims made in the paper. • The abstract and/or introduction should clearly state the claims made, including the contributions made in the paper and important assumptions and limitations. A No or NA answer to this question will not be perceived well by the reviewers. • The claims made should match theoretical and experimental results, and reflect how much the results can be expected to generalize to other settings. • It is fine to include aspirational goals as motivation as long as it is clear that these goals are not attained by the paper. . ","Justification: The justification provided by the authors for the question does not align with what is traditionally expected in a scientific paper and contradicts the content presented in the abstract and introduction of the paper provided. The abstract and introduction of the paper clearly introduce the Meta-Album, a multi-domain meta-dataset designed for facilitating research in few-shot learning, cross-domain learning, and other tasks. They make several claims regarding its size, diversity, and utility for benchmarking few-shot learning algorithms. Therefore, the claim in the justification that they haven't mentioned the main claims in the abstract and introduction is incorrect.

Constructive and Actionable Suggestions:
1. Re-examine the abstract and introduction to identify the main claims made about the contributions and scope of the paper. Clarify these aspects in the answer to accurately reflect the paper's content.
2. Ensure that the claims made in the abstract and introduction are clearly outlined and directly relate to the contributions and scope detailed in the paper. This includes discussing the design and utility of Meta-Album, its comparison with similar efforts, and its role in advancing few-shot learning research.
3. Provide specific information in the abstract and introduction regarding the number of datasets included, the domains they cover, and how the Meta-Album facilitates the proposed research tasks. This will align the claims with the paper's contributions and scope.
4. Consider adding a brief overview of the results or findings from using the Meta-Album in few-shot learning problems to strengthen the claims about its utility and impact on relevant fields.
5. If the abstract and introduction are missing any details regarding assumptions, limitations, and how the results generalize to other settings, consider incorporating this information to provide a comprehensive view of the paper's contributions and scope.",0
Does the paper discuss the limitations of the work performed by the authors?,Yes,We have clearly explained the limitations of our work in Section: Discussion and conclusion,"• The answer NA means that the paper has no limitation while the answer No means that the paper has limitations, but those are not discussed in the paper. • The authors are encouraged to create a separate """" section in their paper. • The paper should point out any strong assumptions and how robust the results are to violations of these assumptions (e.g., independence assumptions, noiseless settings, model well-specification, asymptotic approximations only holding locally). The authors should reflect on how these assumptions might be violated in practice and what the implications would be. • The authors should reflect on the scope of the claims made, e.g., if the approach was only tested on a few datasets or with a few runs. In general, empirical results often depend on implicit assumptions, which should be articulated. • The authors should reflect on the factors that influence the performance of the approach. For example, a facial recognition algorithm may perform poorly when image resolution is low or images are taken in low lighting. Or a speech-to-text system might not be used reliably to provide closed captions for online lectures because it fails to handle technical jargon. • The authors should discuss the computational efficiency of the proposed algorithms and how they scale with dataset size. • If applicable, the authors should discuss possible limitations of their approach to address problems of privacy and fairness. • While the authors might fear that complete honesty about limitations might be used by reviewers as grounds for rejection, a worse outcome might be that reviewers discover limitations that aren't acknowledged in the paper. The authors should use their best judgment and recognize that individual actions in favor of transparency play an important role in developing norms that preserve the integrity of the community. Reviewers will be specifically instructed to not penalize honesty concerning limitations. . ","The response provided by the authors stating that they have clearly explained the limitations of their work in the ""Discussion and conclusion"" section is consistent with the guidelines for discussing limitations. Acknowledging limitations, according to the guidelines, is an essential part of a scientific paper. It helps in providing a transparent view of the work to the readers and also indicates the areas of potential improvement or further investigation.

From the provided content summary, it seems the paper has adhered to the guidelines well by including a section dedicated to discussing the limitations, although the specific details of these limitations were not provided in the summary. This approach by the authors signifies a commitment to academic honesty and enhances the paper's credibility by acknowledging areas where the work might not hold strong or where the scope is limited.

However, it is crucial to note that merely stating that limitations are discussed is not sufficient—what matters is the depth and honesty of these discussions. Since the detailed content of the ""Discussion and conclusion"" section was not provided, it's essential to trust the authors at their word in this review context. Future reviews could benefit from more specific insights into how the limitations were addressed in that section.

Constructive suggestions for the authors:
1. Ensure that the limitations discussed are specific and detailed, addressing all relevant aspects as outlined in the guidelines (e.g., assumptions made, scope of claims, computational efficiency).
2. Consider potential improvements or future lines of investigation to address these limitations, providing a road map for future work in the area.
3. Reflect on the broader implications of these limitations for the applicability of the approach in real-world scenarios and its potential impact on privacy, fairness, and other ethical considerations.
4. If not already done, including examples or case studies where these limitations might significantly affect outcomes can provide practical insights into their importance.",1
"For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof?",Yes,We have detailed all the theoretical proofs in the main paper.,"• The answer NA means that the paper does not include theoretical results. • All the theorems, formulas, and proofs in the paper should be numbered and crossreferenced. • All assumptions should be clearly stated or referenced in the statement of any theorems. • The proofs can either appear in the main paper or the supplemental material, but if they appear in the supplemental material, the authors are encouraged to provide a short proof sketch to provide intuition. • Inversely, any informal proof provided in the core of the paper should be complemented by formal proofs provided in appendix or supplemental material. • Theorems and Lemmas that the proof relies upon should be properly referenced. . ","Justification: The authors' justification is too generic and does not specify where the theoretical proofs can be found, nor does it address whether all assumptions are clearly stated or if they have provided sketches or intuition for the proofs in the main content when detailed proofs are in the supplemental material. Furthermore, there's no mention of whether theorems and lemmas which the proofs rely upon are properly referenced. Given the guidelines, a more detailed response is required to ensure that the paper adheres to the standards for presenting theoretical results.

Constructive and Actionable Suggestions:
1. Clearly indicate in your response the location of the theoretical proofs within the paper or supplemental material. If they are located in the supplemental material, consider adding proof sketches or intuitive explanations in the main body to give readers a clearer understanding.

2. Ensure all assumptions underlying your theoretical results are explicitly stated or referenced within the statements of any theorems. It would help if you revised your response to explicitly affirm this, providing section numbers or page references where these can be found.

3. Review your paper to ensure that all theorems, formulas, and proofs are properly numbered and cross-referenced for ease of navigation. This information should be included in your response to provide clear guidance to reviewers and readers.

4. If your theoretical results rely on existing theorems and lemmas, make sure these are appropriately cited. Your response should explicitly state that all necessary references are included, possibly with a brief mention of key references for critical results.

By addressing these points in both your paper and your response to the checklist question, you can significantly improve the transparency and rigor of your presentation of theoretical results.",0
Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)?,No,Our work is proprietary and we are not making the code and data available for public,"• The answer NA means that paper does not include experiments requiring code. • Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details. • While we encourage the release of code and data, we understand that this might not be possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark). • The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details. • The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc. • The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why. • At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). • Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. . ","The justification provided by the authors for not fully disclosing information needed to reproduce the main experimental results contradicts the NeurIPS guidelines which encourage transparency and reproducibility in research, even if releasing code and data is not possible. The statement ""Our work is proprietary and we are not making the code and data available for public"" does not align with the expectations for a research paper aimed at contributing to the scientific community, where sharing methodologies and results for verification and further research is crucial.

Constructive and Actionable Suggestions:
1. **Anonymized Code and Data**: If possible, the authors should consider providing anonymized versions of the code and data that preserve proprietary interests while still allowing for the reproduction of results.
2. **Detailed Methodology Description**: In the absence of code and data, it’s paramount that the paper includes a highly detailed description of the methodology, including mathematical formulations, algorithmic steps, and parameter settings to enable others to independently recreate the experiments.
3. **Synthetic or Public Dataset**: If sharing the original dataset is not possible, authors could evaluate their methods on a synthetic dataset or a publicly available dataset that doesn't compromise proprietary information but still demonstrates the efficacy of their methods.
4. **Pseudocode**: Including detailed pseudocode for any novel algorithms or methods proposed in the paper can help others understand and potentially replicate the research.
5. **Environment and Dependency Details**: Even if the code is not available, providing information about the software environment, library versions, and any other dependencies can help in reproducing the results with a similar setup.
6. **Results and Intermediate Data**: Sharing detailed results, including intermediate steps if applicable, can help others in trying to replicate the study. This might include sharing statistical analysis, model outputs, or any other data that supports the paper's conclusions without revealing proprietary information.
7. **Engagement for Clarity**: Finally, authors could offer to provide additional clarifications via email or supplementary materials to interested researchers trying to replicate the work while maintaining anonymity.

By adhering more closely to the NeurIPS guidelines and adopting some of these suggestions, the authors could enhance the reproducibility of their work and contribute more effectively to the scientific discourse.",0
"Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material?",No,Our work is proprietary and we are not making the code and data available for public,"• The answer NA means that paper does not include experiments requiring code. • Please see the NeurIPS code and data submission guidelines (https://nips.cc/ public/guides/CodeSubmissionPolicy) for more details. • While we encourage the release of code and data, we understand that this might not be possible, so “No” is an acceptable answer. Papers cannot be rejected simply for not including code, unless this is central to the contribution (e.g., for a new open-source benchmark). • The instructions should contain the exact command and environment needed to run to reproduce the results. See the NeurIPS code and data submission guidelines (https: //nips.cc/public/guides/CodeSubmissionPolicy) for more details. • The authors should provide instructions on data access and preparation, including how to access the raw data, preprocessed data, intermediate data, and generated data, etc. • The authors should provide scripts to reproduce all experimental results for the new proposed method and baselines. If only a subset of experiments are reproducible, they should state which ones are omitted from the script and why. • At submission time, to preserve anonymity, the authors should release anonymized versions (if applicable). • Providing as much information as possible in supplemental material (appended to the paper) is recommended, but including URLs to data and code is permitted. . ","The justification provided by the authors conflicts with the content available in the paper. The paper explicitly mentions the availability of source code, baseline methods, data loaders, and instructions for contributing either new datasets or algorithms to their expandable meta-dataset on their website (https://meta-album.github.io/). This indicates that the authors have made efforts to ensure open access to the data and code necessary for reproducing the main experimental results. Moreover, the GitHub repository linked (https://github.com/ihsanullah/meta-album) provides additional resources supporting this claim. Therefore, stating that the work is proprietary and not publicly available contradicts the paper's content.

Constructive and Actionable Suggestions:
1. Clarify the availability of code and data in the justification to align with the content provided in the paper and supplementary materials.
2. Ensure that the GitHub repository and the website mentioned are accessible and contain clear instructions for reproducing the experimental results, including environment setup, data preprocessing, and execution commands.
3. If any part of the code or data cannot be made publicly available due to privacy or proprietary reasons, clearly specify these exceptions and provide justification.
4. Consider adding a detailed README file in the GitHub repository outlining step-by-step instructions for installation, configuration, and execution of the experiments to facilitate ease of reproducibility.
5. If any third-party datasets or tools are used, include instructions or scripts for obtaining these resources and properly attribute them in both the paper and the repository.
6. To improve transparency and reproducibility, consider including a requirements.txt or an environment.yml file in the repository to specify the exact versions of the software and libraries used in the experiments.",0
"Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results?",Yes,We have explained the experimental settings or details in Section 3.2: Experiments.,"• The answer NA means that the paper does not include experiments. • The experimental setting should be presented in the core of the paper to a level of detail that is necessary to appreciate the results and make sense of them. • The full details can be provided either with the code, in appendix, or as supplemental material. . ","The justification provided in the response, stating that the experimental settings are explained in Section 3.2: Experiments, is somewhat vague and does not explicitly confirm whether all necessary training and test details (e.g., data splits, hyperparameters, their selection process, type of optimizer, etc.) are specified in detail. While the paper does seem to provide an extensive overview of the Meta-Album dataset, its various versions, and a broad description of experiments conducted, the specific details necessary to fully replicate the experiments and understand the results are not enumerated clearly in the response.

Constructive and Actionable Suggestions:
1. Expand the justification to include specific information about how the data splits were created (for both training and testing), including any stratification or randomization process used.
2. Clarify the selection process for hyperparameters: Were they chosen based on prior literature, optimized through cross-validation, or another method? Providing this information would greatly add to the reproducibility of the experiments.
3. Specify the type of optimizer used for the experiments, including any relevant configurations such as learning rate, decay schedules, etc.
4. If this information is indeed included in Section 3.2 but was not detailed in the response, revising the response to outline these details explicitly would strengthen it.
5. If these details are provided elsewhere, such as an appendix or supplemental materials, including references to these resources in the response would be helpful. If they are not provided at all, consider adding this information to the paper or supplemental materials to enhance the clarity and reproducibility of the research.",0
Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments?,Yes,We have reported error bars in Section 3.2: Experiments.,"• The answer NA means that the paper does not include experiments. • The authors should answer ""Yes"" if the results are accompanied by error bars, confidence intervals, or statistical significance tests, at least for the experiments that support the main claims of the paper. • The factors of variability that the error bars are capturing should be clearly stated (for example, train/test split, initialization, random drawing of some parameter, or overall run with given experimental conditions). • The method for calculating the error bars should be explained (closed form formula, call to a library function, bootstrap, etc.) • The assumptions made should be given (e.g., Normally distributed errors). • It should be clear whether the error bar is the standard deviation or the standard error of the mean. • It is OK to report 1-sigma error bars, but one should state it. The authors should preferably report a 2-sigma error bar than state that they have a 96% CI, if the hypothesis of Normality of errors is not verified. • For asymmetric distributions, the authors should be careful not to show in tables or figures symmetric error bars that would yield results that are out of range (e.g. negative error rates). • If error bars are reported in tables or plots, The authors should explain in the text how they were calculated and reference the corresponding figures or tables in the text. . ","The authors have indicated that they reported error bars in Section 3.2: Experiments, which is in line with the guidelines provided for reporting statistical significance. However, the detailed review of the paper content and the extensive use of error bars and confidence intervals throughout the experimental results sections supports the correctness of their statement. Particularly, the paper includes tables and figures where error bars are explicitly shown (e.g., Tables 5-8, Figures 11-13), and the text mentions the computation of 95% confidence intervals, which fulfill the requirements stated in the guidelines.

The paper could enhance its statistical reporting by further detailing the calculation methods for error bars, including any assumptions made (such as normality of errors) and specifying whether they represent standard deviations or standard errors of the mean. Including such details would ensure readers have a complete understanding of the statistical significance of the results presented.

Constructive and actionable suggestions for the authors:
1. Explicitly state the method used for calculating the error bars and confidence intervals in the text. Specify if they represent standard deviations or standard errors of the mean.
2. Include a discussion on the assumptions made for the statistical methods used, such as normality of errors.
3. If applicable, consider addressing how variability factors (e.g., initialization, dataset splits) were accounted for in the error bar calculations.
4. Ensure references to figures and tables that contain error bars are clearly indicated in the relevant sections discussing experimental results.
5. For asymmetric distributions, carefully consider and possibly report asymmetric error bars to accurately represent the variability in the data.

These suggestions aim to further strengthen the statistical significance reporting in the paper, ensuring clarity and comprehensiveness for the readers.",1
"For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments?",Yes,"We have provided details about compute resources used in Section 3.2: Experiments, Appendix E: Within Domain Few-shot learning, and Appendix F: Cross-Domain Few-shot learning","• The answer NA means that the paper does not include experiments. • The paper should indicate the type of compute workers CPU or GPU, internal cluster, or cloud provider, including relevant memory and storage. • The paper should provide the amount of compute required for each of the individual experimental runs as well as estimate the total compute. • The paper should disclose whether the full research project required more compute than the experiments reported in the paper (e.g., preliminary or failed experiments that didn't make it into the paper). . ","The justification provided by the authors that they have detailed the compute resources in Section 3.2, Appendix E, and Appendix F does not fully align with the requirement specified in the question and the guidelines. While the paper mentions some aspects of the computational resources and settings, it lacks comprehensive details considering the guidelines' requirement for explicit information about the type of compute workers (CPU or GPU, internal cluster, or cloud provider), memory, storage, and a thorough breakdown of computational requirements for individual experiments. This information is crucial for ensuring the reproducibility of experiments.

Constructive and actionable suggestions:
1. **Specify Compute Workers:** Clearly indicate the type of CPUs or GPUs used for the experiments, including the model names and specifications. If the experiments were conducted on an internal cluster or a cloud provider, please specify this detail.
   
2. **Detail Memory and Storage:** Provide information about the memory (RAM) and storage capacity available for the compute resources utilized during the experiments. This detail helps in understanding if the experiments can be reproduced on machines with lower or similar specifications.

3. **Breakdown Compute Requirements:** For each experiment or set of experiments, include a breakdown of compute requirements, mentioning the execution time for individual experimental runs. For experiments leveraging GPUs, mention the number of GPUs used and the impact on execution time if any.

4. **Disclose Preliminary or Failed Experiments:** If applicable, mention any preliminary or failed experiments not included in the paper but which contributed to the computational load of the project. This disclosure provides a clearer picture of the overall compute resources required for the research project.

5. **Consider Adding a Dedicated Section or Table:** To organize the information efficiently, consider adding a dedicated section or a table summarizing the computational resources used across all experiments. This approach facilitates easy reference for readers aiming to reproduce the experiments.

By addressing these suggestions, the paper can provide a more comprehensive view of the computational resources required, enhancing transparency and reproducibility.",0
"Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics https://neurips.cc/public/EthicsGuidelines?",No,We are not bound to follow the NeurIPS code of ethics,"• The answer NA means that the authors have not reviewed the NeurIPS Code of Ethics. • If the authors answer No, they should explain the special circumstances that require a deviation from the Code of Ethics. • The authors should make sure to preserve anonymity (e.g., if there is a special consideration due to laws or regulations in their jurisdiction). . ","Justification for Score:
The answer provided by the authors stating they are ""not bound to follow the NeurIPS code of ethics"" is inconsistent with the standards expected from a submission to the NeurIPS conference. Acknowledging and adhering to the NeurIPS Code of Ethics is crucial for maintaining the integrity, quality, and respectability of the research presented at the conference, and it applies to all participants without exception. The authors' justification for not following the Code of Ethics lacks an explanation of any special circumstances that might justify such a deviation, as outlined in the provided guidelines.

Constructive and Actionable Suggestions:
1. Review and Understand the Code of Ethics: The authors should thoroughly review the NeurIPS Code of Ethics to understand the responsibilities and standards expected from all participants. This ensures that the research aligns with ethical guidelines promoting integrity, respect, and fair conduct.

2. Provide a Clear Justification: If there are specific reasons or special circumstances that prevent adherence to the Code of Ethics (e.g., legal restrictions, cultural considerations), these should be clearly articulated in the paper, providing context to reviewers and readers.

3. Amend the Research Methodology if Necessary: If any part of the research does not comply with the Code of Ethics due to oversight or misunderstanding, the authors should consider revising their methodology or approach to ensure compliance.

4. Reassess the Impact of Non-Compliance: The authors should carefully consider the implications of not adhering to the NeurIPS Code of Ethics, particularly how it might affect the credibility of their research, the potential harm to subjects or participants, and the reception of their work by the broader research community.

5. Include an Ethics Statement: The authors should include a detailed ethics statement in their paper, outlining how they have addressed ethical considerations relevant to their research, demonstrating a commitment to ethical conduct.

By taking these steps, the authors can ensure that their research not only contributes valuable insights to the field but also upholds the highest ethical standards set by the NeurIPS community.",0
Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed?,Yes,We have detailed potential impacts and recommended use in Section 1.3,"• The answer NA means that there is no societal impact of the work performed. • If the authors answer NA or No, they should explain why their work has no societal impact or why the paper does not address societal impact. • Examples of negative societal impacts include potential malicious or unintended uses (e.g., disinformation, generating fake profiles, surveillance), fairness considerations (e.g., deployment of technologies that could make decisions that unfairly impact specific groups), privacy considerations, and security considerations. • The conference expects that many papers will be foundational research and not tied to particular applications, let alone deployments. However, if there is a direct path to any negative applications, the authors should point it out. For example, it is legitimate to point out that an improvement in the quality of generative models could be used to generate deepfakes for disinformation. On the other hand, it is not needed to point out that a generic algorithm for optimizing neural networks could enable people to train models that generate Deepfakes faster. • The authors should consider possible harms that could arise when the technology is being used as intended and functioning correctly, harms that could arise when the technology is being used as intended but gives incorrect results, and harms following from (intentional or unintentional) misuse of the technology. • If there are negative societal impacts, the authors could also discuss possible mitigation strategies (e.g., gated release of models, providing defenses in addition to attacks, mechanisms for monitoring misuse, mechanisms to monitor how a system learns from feedback over time, improving the efficiency and accessibility of ML). . ","The justification provided by the authors mentions Section 1.3 for potential impacts and recommended use, but it does not explicitly state whether they have discussed both potential positive and negative societal impacts as inquired in the question. Based on the provided content and guidelines, it is critical for a paper that introduces a new dataset or technology to consider and explicitly discuss both the positive and negative societal impacts of their work. This includes not just the intended positive applications and benefits but also potential misuses, fairness considerations, privacy, security concerns, and strategies for mitigating any identified negative impacts.

Constructive and actionable suggestions for the authors would include:
1. Explicitly identify and discuss potential positive impacts of the Meta-Album dataset on the societal level, such as advancements in computer vision research, improvements in image classification technologies, contributions to academic research, and any other applications that benefit society.
2. Identify and elaborate on potential negative societal impacts of the Meta-Album dataset or technologies developed using it. This could include misuse of the dataset for developing technology with harmful intentions, biases in the dataset that could lead to unfairness in model outcomes, privacy issues related to the images included, and any other concerns related to ethics and societal harm.
3. Discuss mitigation strategies for any identified negative societal impacts. This could involve recommendations for responsible use, guidelines for researchers to avoid or minimize biases, privacy safeguards, and any measures to prevent misuse of the dataset.
4. Provide specific sections or subsections in the paper where these discussions are held, ensuring that readers can easily find and understand the authors' considerations regarding societal impacts.
5. Consider adding an ethical considerations section if not already included, which could comprehensively cover the discussion on societal impacts and mitigation strategies.

By addressing these suggestions, the authors could make their discussion on societal impacts more comprehensive and explicit, which would strengthen the paper's contribution to both the scientific community and society at large.",0
"Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse (e.g., pretrained language models, image generators, or scraped datasets)?",Yes,"Indeed, we are releasing our datasets with proper license and terms of use. We have also provided recommended usage of these datasets.","• The answer NA means that the paper poses no such risks. • Released models that have a high risk for misuse or dual-use should be released with necessary safeguards to allow for controlled use of the model, for example by requiring that users adhere to usage guidelines or restrictions to access the model or implementing safety filters. • Datasets that have been scraped from the Internet could pose safety risks. The authors should describe how they avoided releasing unsafe images. • We recognize that providing effective safeguards is challenging, and many papers do not require this, but we encourage authors to take this into account and make a best faith effort. . ","The authors correctly stated that they are releasing their datasets with proper license and terms of use. This implies that they have considered the potential for misuse and have taken steps to mitigate such risks by establishing clear guidelines for the responsible use of their data. This approach aligns with the guidelines provided, emphasizing the importance of safeguards for the responsible release of datasets.

However, while the answer and justification provided by the authors are consistent with the guidelines and demonstrate an awareness of the need for responsible data release, a more detailed explanation of the specific safeguards or terms of use could strengthen the response. For example, mentioning the type of licenses under which the datasets are released and any specific restrictions or obligations these licenses entail would offer a clearer picture of the safeguards in place.

Constructive suggestions for the authors to enhance their response include:
1. Specify the types of licenses under which the datasets are released and highlight any key provisions that help prevent misuse.
2. If applicable, describe any additional measures taken to ensure responsible usage, such as user agreements, access restrictions, or mechanisms for reporting misuse.
3. Provide examples or scenarios illustrating how the recommended usage guidelines help mitigate the risk of misuse.
4. Discuss any considerations or challenges encountered in implementing safeguards for the datasets and how these were addressed.

These suggestions aim to provide the authors with actionable advice on how to more thoroughly document and communicate the safeguards they have implemented, thereby enhancing transparency and reinforcing their commitment to responsible data release.",1
"Are the creators or original owners of assets (e.g., code, data, models), used in the paper, properly credited and are the license and terms of use explicitly mentioned and properly respected?",Yes,"We are releasing our datasets with proper license, we are also mentioning the original licenses for the original datasets in Appendix B: License information of Meta-Album datasets","• The answer NA means that the paper does not use existing assets. • The authors should cite the original paper that produced the code package or dataset. • The authors should state which version of the asset is used and, if possible, include a URL. • The name of the license (e.g., CC-BY 4.0) should be included for each asset. • For scraped data from a particular source (e.g., website), the copyright and terms of service of that source should be provided. • If assets are released, the license, copyright information, and terms of use in the package should be provided. For popular datasets, paperswithcode.com/datasets has curated licenses for some datasets. Their licensing guide can help determine the license of a dataset. • For existing datasets that are re-packaged, both the original license and the license of the derived asset (if it has changed) should be provided. • If this information is not available online, the authors are encouraged to reach out to the asset's creators. . ","The authors have indeed respected the guidelines for crediting the original creators and mentioning the licenses and terms of use of the assets used in the paper. Appendix B, as referenced in the justification, specifically addresses the requirement to mention the original licenses for the datasets included in Meta-Album, thereby fulfilling the requirement to properly credit the creators and respect the licenses.

However, to further improve transparency and compliance with the guidelines, the authors may consider the following suggestions:
1. **Explicitly Mention the License Type in the Main Text**: While Appendix B contains detailed license information, a brief mention of the licensing approach (e.g., open licenses like CC-BY or more restrictive ones) in the main text could increase visibility and awareness.
2. **Provide Direct Links to Original Licenses**: If feasible, directly link to the web pages or documents where the original licenses are detailed for each dataset. This would make it easier for readers and users of the Meta-Album dataset to understand the terms of use.
3. **Clarify the License for the New Meta-Album Dataset**: Clarify under which license the new Meta-Album dataset is released. Mentioning this explicitly in both the appendix and the main text ensures users understand how they can use Meta-Album and any derived assets.
4. **Versioning and URL Guidelines**: Ensure that, for each dataset included, the version used is specified along with a stable URL when possible. This aids reproducibility and allows users to locate the exact version of the datasets used.

Implementing these suggestions would enhance the paper's adherence to best practices for asset use and sharing, making it a more valuable resource for the research community.",1
Are new assets introduced in the paper well documented and is the documentation provided alongside the assets?,Yes,We have properly documented our new datasets using meta-data files and datasheets for datasets (provided in the appendices).,"• The answer NA means that the paper does not release new assets. • Researchers should communicate the details of the dataset/code/model as part of their submissions via structured templates. This includes details about training, license, limitations, etc. • The paper should discuss whether and how consent was obtained from people whose asset is used. • At submission time, remember to anonymize your assets (if applicable). You can either create an anonymized URL or include an anonymized zip file. . ","The authors' answer is consistent with the content provided in the paper. The paper outlines a thorough documentation practice for the introduced datasets, including the use of meta-data files and datasheets detailed in the appendices. This approach aligns well with the guidelines for documenting new assets introduced in research work. 

However, it's important to note that the answer could have been richer if it explicitly mentioned the accessibility of this documentation for interested researchers (e.g., through a public repository or a dedicated webpage for the Meta-Album project). 

Suggestions for improvement:
1. Specify where the documentation can be accessed. Providing URLs or references to the specific appendices within the paper can make it easier for readers to find this information.
2. Elaborate on the content of the documentation. Briefly describe what information is included in the meta-data files and datasheets to give readers an understanding of what to expect.
3. Address consent and licensing explicitly in the documentation. Even though the paper mentions checking the original owners for usage permission, explicitly stating the licensing information for each dataset (e.g., in the datasheets) would enhance transparency and usability for future researchers.",1
"For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants and screenshots, if applicable, as well as details about compensation (if any)?",Yes,We have mentioned all the crowdsourcing details in the main paper,"• The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. • Including this information in the supplemental material is fine, but if the main contribution of the paper involves human subjects, then as much detail as possible should be included in the main paper. • According to the NeurIPS Code of Ethics, workers involved in data collection, curation, or other labor should be paid at least the minimum wage in the country of the data collector. . ","The answer provided by the authors is inconsistent with the detailed review of the paper content. There is no specific mention or section in the provided content that directly addresses the full text of instructions given to participants, screenshots of the process, or details about compensation for crowdsourcing experiments and research with human subjects. Furthermore, the paper primarily focuses on introducing the Meta-Album meta-dataset for few-shot learning and does not explicitly detail any direct engagement with human subjects or crowdsourcing activities related to data collection or annotation within the sections provided.

Constructive and actionable suggestions:
1. If the paper involves human subjects or crowdsourcing efforts in any phase of the dataset creation, annotation, or experiment setup, explicitly detail this aspect. Include a separate section or a paragraph within the relevant sections to describe the procedures followed, instructions given to participants, screenshots where applicable, and compensation details.
2. Clarify whether human subjects were involved only in indirect ways, such as through the use of pre-existing datasets that might have involved human annotation efforts. If so, acknowledge these contributions appropriately and provide references to the source datasets where these details can be found.
3. In case there was a misunderstanding, and the paper does not directly involve crowdsourcing experiments or research with human subjects, consider updating the response to NA, clearly justifying why it does not apply to the work presented.
4. For future submissions or revisions, consider the importance of transparency when it comes to involving human subjects, following ethical guidelines, and the impact of acknowledging contributors' efforts adequately.",0
"Does the paper describe potential risks incurred by study participants, whether such risks were disclosed to the subjects, and whether Institutional Review Board (IRB) approvals (or an equivalent approval/review based on the requirements of your country or institution) were obtained?",Yes,We have received approvals from IRB and have mentioned in the main paper,"• The answer NA means that the paper does not involve crowdsourcing nor research with human subjects. • Depending on the country in which research is conducted, IRB approval (or equivalent) may be required for any human subjects research. If you obtained IRB approval, you should clearly state this in the paper. • We recognize that the procedures for this may vary significantly between institutions and locations, and we expect authors to adhere to the NeurIPS Code of Ethics and the guidelines for their institution. • For initial submissions, do not include any information that would break anonymity (if applicable), such as the institution conducting the review.","Justification:
The given answer and justification provided by the authors are inconsistent with the paper content based on several factors:
1. The paper does not involve direct human subjects or crowdsourcing research that would typically necessitate IRB approval. Instead, it introduces a newly formulated meta-dataset, ""Meta-Album,"" designed for few-shot learning applications in machine learning. The creation and usage of such a dataset primarily involve computational experiments without direct interaction with human subjects.
2. The authors' claim of having mentioned IRB approvals in the main paper cannot be verified within the provided content. A thorough review of the paper content does not reveal any section discussing IRB approval, potential risks to study participants, or ethical considerations related to human subjects.

Constructive and Actionable Suggestions:
- Clarify the nature of the research: If the research indeed involves human participants in any capacity not evident from the provided content, please clearly describe the specific aspects that involve human subjects. Clarification will help in understanding the necessity of IRB approval.
- Provide specific details regarding IRB approval: If IRB approval was mistakenly claimed due to a misunderstanding of the question's intent (focusing on research involving human participants or crowdsourcing), kindly correct the response to reflect the actual nature of the study. If IRB approval was obtained for a component of the study not evident in the provided content, consider adding a section that clearly outlines this aspect, including the role of human participants and the measures taken to ensure their privacy and safety.
- Enhance the section on ethical considerations: Even in computational research, addressing ethical considerations is essential, especially when dealing with datasets that could potentially include sensitive information or indirectly involve human-generated data. Add a discussion on any ethical considerations related to the creation, usage, and sharing of the Meta-Album dataset, even if it does not involve direct human subject research.
- Adhere to transparency and reproducibility: Ensure that the paper transparently reports all relevant details about the dataset's compilation, including sourcing, preprocessing, and any interactions with existing human-generated data. This transparency is crucial for enabling reproducibility and ethical usage of the dataset by the research community.",0
